{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diqnfl777/2022F-Ajou-ML-TEAM3/blob/main/LibraryModelFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pARbP1JFJ1LI"
      },
      "source": [
        "# KoBERT finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P4OehJHMJ1c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6862fb8e-cf44-4544-bdfe-18a8ce13a26d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (7.7.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (3.6.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (3.0.3)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (7.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.3.4)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.0.4)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 27.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (2.0.10)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (1.15.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (5.7.16)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.3)\n",
            "Requirement already satisfied: nbconvert<6.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.6.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.2)\n",
            "Requirement already satisfied: jinja2<=3.0.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.11.3)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.15.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2<=3.0.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.0.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-fxgx5ozl\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-fxgx5ozl\n",
            "Collecting boto3<=1.15.18\n",
            "  Downloading boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 31.1 MB/s \n",
            "\u001b[?25hCollecting gluonnlp<=0.10.0,>=0.6.0\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 65.8 MB/s \n",
            "\u001b[?25hCollecting mxnet<=1.7.0.post2,>=1.4.0\n",
            "  Downloading mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.7 MB 89.2 MB/s \n",
            "\u001b[?25hCollecting onnxruntime<=1.8.0,==1.8.0\n",
            "  Downloading onnxruntime-1.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 49.8 MB/s \n",
            "\u001b[?25hCollecting sentencepiece<=0.1.96,>=0.1.6\n",
            "  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 84.9 MB/s \n",
            "\u001b[?25hCollecting torch<=1.10.1,>=1.7.0\n",
            "  Downloading torch-1.10.1-cp38-cp38-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.1 MB/s eta 0:00:43tcmalloc: large alloc 1147494400 bytes == 0x3a804000 @  0x7fe3cc86a615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x4fdff5 0x49caa1 0x4fdff5 0x49ced5 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x5d7c18 0x5d9412 0x586636 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69 0x5d7c18 0x49ca7c 0x4fdff5 0x49ced5\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 8.0 kB/s \n",
            "\u001b[?25hCollecting transformers<=4.8.1,>=4.8.1\n",
            "  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 82.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.12)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting botocore<1.19.0,>=1.18.18\n",
            "  Downloading botocore-1.18.18-py2.py3-none-any.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 63.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.32)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (21.3)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.23.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.1.1)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.64.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.8.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 59.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (3.0.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.2.0)\n",
            "Building wheels for collected packages: kobert, gluonnlp, sacremoses\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15708 sha256=120d84c7b70c9795eca6a32b769a0d2da1d7077fad3ae02ccf23ab7df6382a59\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5ry1c7n8/wheels/bf/5f/74/81bf3a1332130eb6629ecf58876a8746b77021e7d7b0638e91\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp38-cp38-linux_x86_64.whl size=619623 sha256=6197d0822a5b300bd6a885af9e6df58215ca3e6d1fbc8ae1ee27566d2626ee7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/93/9d/2237550c409eb3ed725d6302b7897ddd9a037b40cef66dcd9c\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=6f31c5fed82d56e3fb5db05e1a403f8b0b41b086e76a8a718dd277c20f860613\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built kobert gluonnlp sacremoses\n",
            "Installing collected packages: jmespath, botocore, tokenizers, sacremoses, s3transfer, huggingface-hub, graphviz, transformers, torch, sentencepiece, onnxruntime, mxnet, gluonnlp, boto3, kobert\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.15.18 botocore-1.18.18 gluonnlp-0.10.0 graphviz-0.8.4 huggingface-hub-0.0.12 jmespath-0.10.0 kobert-0.2.3 mxnet-1.7.0.post2 onnxruntime-1.8.0 s3transfer-0.3.7 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.10.3 torch-1.10.1 transformers-4.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ipywidgets  # for vscode\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import 및 사전준비"
      ],
      "metadata": {
        "id": "YsJTAx5FhjhY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6Vn5bcTOJ1dD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SQ7nWEFdJ1dF"
      },
      "outputs": [],
      "source": [
        "from kobert import get_tokenizer\n",
        "from kobert import get_pytorch_kobert_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TPZqVOEgJ1dJ"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "Q5dPe1KZcEmB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "jSnu1VOCJ1dQ"
      },
      "outputs": [],
      "source": [
        "## GPU\n",
        "device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-D3gwc-GJ1dS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de4891cb-c6dc-4042-dc71-eeb2493c5222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_v1.zip\n",
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ],
      "source": [
        "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9FlLragKH7C"
      },
      "source": [
        "# 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EpXK3nnOrDy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069d813a-5480-4e96-dfb4-44e05ed073a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "B-ibCF9LKVVj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b48d97f9-ad9a-4e16-fe41-b0f37049b498"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_column(loc, value, pi)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      제목  청구번호  \\\n",
              "0                      어디서 무엇이 되어 다시 만나랴     9   \n",
              "1                            나의 사랑 클레멘타인     9   \n",
              "2                       초파리를 알면 유전자가 보인다     5   \n",
              "3                              아웃사이더의 반란     3   \n",
              "4          브랜드 인문학 :잠재된 표현 욕망을 깨우는 감각 수업     7   \n",
              "...                                  ...   ...   \n",
              "71533                          한국 시극사 연구     9   \n",
              "71534  조선의 서정시인 퇴계 이황 : 우리가 몰랐던 퇴계의 남도여행     9   \n",
              "71535            내면기행 : 선인들, 스스로 묘비명을 쓰다    10   \n",
              "71536                        뉴 스토리 뉴 스타일     0   \n",
              "71537           (채용담당자가 공개하는) AI면접 합격 기술     7   \n",
              "\n",
              "                                                      목차  \n",
              "0                    \\n\\n결혼식 ㅣ 아기 ㅣ 신혼기 ㅣ 아내의 머리칼 ㅣ 아...  \n",
              "1                    \\n\\n결혼식 ㅣ 아기 ㅣ 신혼기 ㅣ 아내의 머리칼 ㅣ 아...  \n",
              "2              서문 \\r\\n        서론 \\r\\n제1장   지도\\r\\n제2장 ...  \n",
              "3            한국어판 서문 / 5\\r\\n      프롤로그 / 13\\r\\n제1장 보수...  \n",
              "4           1부-정체성\\r\\n1 프라다: 나의 정체성을 알 때, 비로소 브랜드는 ‘필...  \n",
              "...                                                  ...  \n",
              "71533  ㆍ책머리에 \\r\\n\\r\\n제1장 서론 \\r\\n\\r\\n1. 연구 목적…17 \\r\\n2...  \n",
              "71534  ㆍ책머리에\\r\\n\\r\\n1. 퇴계의 시혼, 남도에서 피다\\r\\n퇴계가 남쪽으로 간 ...  \n",
              "71535  ㆍ책을 엮으며\\r\\n\\r\\n제1부 이사람을 보라\\r\\n제2부 이것으로 만족이다\\r\\...  \n",
              "71536  ㆍ책을 펴내며\\r\\n\\r\\n서 장 새로움을 위해\\r\\n제1장 살인의 추억\\r\\n제2...  \n",
              "71537  ㆍ프롤로그\\tAI면접에 대한 올바른 접근\\r\\n\\r\\nㆍPART 1\\tAI면접이란 ...  \n",
              "\n",
              "[71478 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-962bf070-86fc-4b71-abc5-f91589894d80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>제목</th>\n",
              "      <th>청구번호</th>\n",
              "      <th>목차</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>어디서 무엇이 되어 다시 만나랴</td>\n",
              "      <td>9</td>\n",
              "      <td>\\n\\n결혼식 ㅣ 아기 ㅣ 신혼기 ㅣ 아내의 머리칼 ㅣ 아...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>나의 사랑 클레멘타인</td>\n",
              "      <td>9</td>\n",
              "      <td>\\n\\n결혼식 ㅣ 아기 ㅣ 신혼기 ㅣ 아내의 머리칼 ㅣ 아...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>초파리를 알면 유전자가 보인다</td>\n",
              "      <td>5</td>\n",
              "      <td>서문 \\r\\n        서론 \\r\\n제1장   지도\\r\\n제2장 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>아웃사이더의 반란</td>\n",
              "      <td>3</td>\n",
              "      <td>한국어판 서문 / 5\\r\\n      프롤로그 / 13\\r\\n제1장 보수...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>브랜드 인문학 :잠재된 표현 욕망을 깨우는 감각 수업</td>\n",
              "      <td>7</td>\n",
              "      <td>1부-정체성\\r\\n1 프라다: 나의 정체성을 알 때, 비로소 브랜드는 ‘필...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71533</th>\n",
              "      <td>한국 시극사 연구</td>\n",
              "      <td>9</td>\n",
              "      <td>ㆍ책머리에 \\r\\n\\r\\n제1장 서론 \\r\\n\\r\\n1. 연구 목적…17 \\r\\n2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71534</th>\n",
              "      <td>조선의 서정시인 퇴계 이황 : 우리가 몰랐던 퇴계의 남도여행</td>\n",
              "      <td>9</td>\n",
              "      <td>ㆍ책머리에\\r\\n\\r\\n1. 퇴계의 시혼, 남도에서 피다\\r\\n퇴계가 남쪽으로 간 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71535</th>\n",
              "      <td>내면기행 : 선인들, 스스로 묘비명을 쓰다</td>\n",
              "      <td>10</td>\n",
              "      <td>ㆍ책을 엮으며\\r\\n\\r\\n제1부 이사람을 보라\\r\\n제2부 이것으로 만족이다\\r\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71536</th>\n",
              "      <td>뉴 스토리 뉴 스타일</td>\n",
              "      <td>0</td>\n",
              "      <td>ㆍ책을 펴내며\\r\\n\\r\\n서 장 새로움을 위해\\r\\n제1장 살인의 추억\\r\\n제2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71537</th>\n",
              "      <td>(채용담당자가 공개하는) AI면접 합격 기술</td>\n",
              "      <td>7</td>\n",
              "      <td>ㆍ프롤로그\\tAI면접에 대한 올바른 접근\\r\\n\\r\\nㆍPART 1\\tAI면접이란 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71478 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-962bf070-86fc-4b71-abc5-f91589894d80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-962bf070-86fc-4b71-abc5-f91589894d80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-962bf070-86fc-4b71-abc5-f91589894d80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#데이터 가공\n",
        "#청구기호 숫자 앞 2개만 따와서 각각 매핑. 65~70은 예외적으로 경영학\n",
        "import pandas as pd\n",
        "import re \n",
        "\n",
        "data = pd.read_csv(\"/content/gdrive/MyDrive/LibraryCsv/indexhapbon.csv\",encoding='UTF8',usecols = ['제목', '청구번호','목차'])\n",
        "data = data.loc[:,['제목', '청구번호','목차']]\n",
        "data = data.dropna()\n",
        "data = data.drop_duplicates()\n",
        "\n",
        "\n",
        "data['청구번호'] = data['청구번호'].apply(str)\n",
        "\n",
        "data['청구번호'] = data['청구번호'].replace({r'(.*?)(\\d{2})\\d.*' : r'\\2'}, regex=True)\n",
        "\n",
        "data['청구번호'] = pd.to_numeric(data['청구번호'],errors = 'coerce')\n",
        "data = data.dropna()\n",
        "data.loc[(data['청구번호'] >= 100), ['청구번호']] = None\n",
        "data = data.dropna()\n",
        "data.loc[(data['청구번호'] < 10), ['청구번호']] = 1000\n",
        "data.loc[(data['청구번호'] < 20), ['청구번호']] = 1001\n",
        "data.loc[(data['청구번호'] < 30), ['청구번호']] = 1002\n",
        "data.loc[(data['청구번호'] < 40), ['청구번호']] = 1003\n",
        "data.loc[(data['청구번호'] < 50), ['청구번호']] = 1004\n",
        "data.loc[(data['청구번호'] < 60), ['청구번호']] = 1005\n",
        "data.loc[(data['청구번호'] < 65), ['청구번호']] = 1006 #경영학쪽은 따로 분류이기 떄문에 65 사용\n",
        "data.loc[(data['청구번호'] < 70), ['청구번호']] = 1007 #즉, 1007 쪽이 경영학책\n",
        "data.loc[(data['청구번호'] < 80), ['청구번호']] = 1008\n",
        "data.loc[(data['청구번호'] < 90), ['청구번호']] = 1009\n",
        "data.loc[(data['청구번호'] <  100), ['청구번호']] = 1010\n",
        "\n",
        "labels = {'0':'총류',\n",
        "          '1':'철학',\n",
        "          '2':'종교',\n",
        "          '3':'사회학',\n",
        "          '4':'언어',\n",
        "          '5':'자연과학',\n",
        "          '6':'기술과학',\n",
        "          '7':'경영학',\n",
        "          '8':'예술',\n",
        "          '9':'문학',\n",
        "          '10':'역사'\n",
        "          }\n",
        "\n",
        "data['청구번호'] = data['청구번호']%1000\n",
        "data['청구번호'] = data['청구번호'].astype(int)\n",
        "regex = '[0-9|A-Z|a-z|ㄱ-ㅎ|ㅏ-ㅣ|가-힣|\\s]*[ㄱ-ㅎ|ㅏ-ㅣ|가-힣][0-9|A-Z|a-z|ㄱ-ㅎ|ㅏ-ㅣ|가-힣|\\s]*'\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_sample = data.sample(frac = 0.05, random_state = 5)\n",
        "df_train, df_val, df_test = np.split(data_sample.sample(frac=1, random_state=42), \n",
        "                                     [int(.8*len(data_sample)), int(.9*len(data_sample))])"
      ],
      "metadata": {
        "id": "BIhhncUEaXDr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataSets"
      ],
      "metadata": {
        "id": "ITPGlPdMAiB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
        "en_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "tokenizer = get_tokenizer()\n",
        "kr_tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXzI4D4tNGbJ",
        "outputId": "3c091720-5a93-4360-f95a-48abcc6ea4db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EN_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.labels =  df['청구번호'].values\n",
        "        self.dic = [en_tokenizer(text, padding='max_length', max_length = 64, truncation=True, return_tensors=\"pt\") for text in df['제목']]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.dic[idx]\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y"
      ],
      "metadata": {
        "id": "oL4Ysx7CejSl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KR_BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "metadata": {
        "id": "7dsT-6p6ejvq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Library_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.title_data = []\n",
        "        transform = nlp.data.BERTSentenceTransform(                                 # 한글용\n",
        "            kr_tok, max_seq_length=64, pad=True, pair=False)\n",
        "        for text in df['제목']:\n",
        "          if re.fullmatch(regex, text):\n",
        "            self.title_data.append((np.int32(1),transform(text)))\n",
        "          else:\n",
        "            self.title_data.append((np.int32(0), en_tokenizer(text, padding='max_length', max_length = 64, truncation=True, return_tensors=\"pt\")))\n",
        "        self.index_data = [en_tokenizer(text, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") for text in df['목차']]\n",
        "        self.labels = [np.int32(i) for i in df['청구번호']]\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        lang, item = self.title_data[idx]\n",
        "        return (lang, item ,self.labels[idx], self.index_data[idx])"
      ],
      "metadata": {
        "id": "nTEPG5_uEBsW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampledata = data[:100]"
      ],
      "metadata": {
        "id": "0aCqR43wN9kB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampledata"
      ],
      "metadata": {
        "id": "Hx2EvWjxOH89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e5c2cceb-1410-470f-f22c-981bccaa12ed"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               제목  청구번호  \\\n",
              "0               어디서 무엇이 되어 다시 만나랴     9   \n",
              "1                     나의 사랑 클레멘타인     9   \n",
              "2                초파리를 알면 유전자가 보인다     5   \n",
              "3                       아웃사이더의 반란     3   \n",
              "4   브랜드 인문학 :잠재된 표현 욕망을 깨우는 감각 수업     7   \n",
              "..                            ...   ...   \n",
              "95                         수학의 배신     5   \n",
              "96           (손에 잡히는) 인터넷 비지니스 전략     7   \n",
              "97           마리의 돼지의 낙타 :엄우흠 장편소설     9   \n",
              "98              체리레몬칵테일 :김규나 장편소설     9   \n",
              "99             (현장 적응을 위한) 유공압 이론     6   \n",
              "\n",
              "                                                   목차  \n",
              "0                 \\n\\n결혼식 ㅣ 아기 ㅣ 신혼기 ㅣ 아내의 머리칼 ㅣ 아...  \n",
              "1                 \\n\\n결혼식 ㅣ 아기 ㅣ 신혼기 ㅣ 아내의 머리칼 ㅣ 아...  \n",
              "2           서문 \\r\\n        서론 \\r\\n제1장   지도\\r\\n제2장 ...  \n",
              "3         한국어판 서문 / 5\\r\\n      프롤로그 / 13\\r\\n제1장 보수...  \n",
              "4        1부-정체성\\r\\n1 프라다: 나의 정체성을 알 때, 비로소 브랜드는 ‘필...  \n",
              "..                                                ...  \n",
              "95   1장 거대한 착각   8\\r\\n 2장 무엇을 위해 수학을 공부하는가   24\\r\\...  \n",
              "96   1장 인터넷 이해하기\\n 1. 미래로 가는 길 인터넷\\n 2. 인터넷 혁명\\n 3...  \n",
              "97   1장\\r\\n 영혼이 없는 떡볶이 \\r\\n\\r\\n 2장\\r\\n 대지의 비늘 \\r\\n...  \n",
              "98   1장_7\\r\\n 2장_50\\r\\n 3장_121\\r\\n 4장_211\\r\\n 5장_3...  \n",
              "99  - 1편 유압 - \\n.1장 유압의 기초  \\n.2장 유체 역학의 기초 이론  \\n...  \n",
              "\n",
              "[100 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43dafc14-0baf-45a7-b728-817c3a4b2c09\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>제목</th>\n",
              "      <th>청구번호</th>\n",
              "      <th>목차</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>어디서 무엇이 되어 다시 만나랴</td>\n",
              "      <td>9</td>\n",
              "      <td>\\n\\n결혼식 ㅣ 아기 ㅣ 신혼기 ㅣ 아내의 머리칼 ㅣ 아...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>나의 사랑 클레멘타인</td>\n",
              "      <td>9</td>\n",
              "      <td>\\n\\n결혼식 ㅣ 아기 ㅣ 신혼기 ㅣ 아내의 머리칼 ㅣ 아...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>초파리를 알면 유전자가 보인다</td>\n",
              "      <td>5</td>\n",
              "      <td>서문 \\r\\n        서론 \\r\\n제1장   지도\\r\\n제2장 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>아웃사이더의 반란</td>\n",
              "      <td>3</td>\n",
              "      <td>한국어판 서문 / 5\\r\\n      프롤로그 / 13\\r\\n제1장 보수...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>브랜드 인문학 :잠재된 표현 욕망을 깨우는 감각 수업</td>\n",
              "      <td>7</td>\n",
              "      <td>1부-정체성\\r\\n1 프라다: 나의 정체성을 알 때, 비로소 브랜드는 ‘필...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>수학의 배신</td>\n",
              "      <td>5</td>\n",
              "      <td>1장 거대한 착각   8\\r\\n 2장 무엇을 위해 수학을 공부하는가   24\\r\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>(손에 잡히는) 인터넷 비지니스 전략</td>\n",
              "      <td>7</td>\n",
              "      <td>1장 인터넷 이해하기\\n 1. 미래로 가는 길 인터넷\\n 2. 인터넷 혁명\\n 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>마리의 돼지의 낙타 :엄우흠 장편소설</td>\n",
              "      <td>9</td>\n",
              "      <td>1장\\r\\n 영혼이 없는 떡볶이 \\r\\n\\r\\n 2장\\r\\n 대지의 비늘 \\r\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>체리레몬칵테일 :김규나 장편소설</td>\n",
              "      <td>9</td>\n",
              "      <td>1장_7\\r\\n 2장_50\\r\\n 3장_121\\r\\n 4장_211\\r\\n 5장_3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>(현장 적응을 위한) 유공압 이론</td>\n",
              "      <td>6</td>\n",
              "      <td>- 1편 유압 - \\n.1장 유압의 기초  \\n.2장 유체 역학의 기초 이론  \\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43dafc14-0baf-45a7-b728-817c3a4b2c09')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43dafc14-0baf-45a7-b728-817c3a4b2c09 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43dafc14-0baf-45a7-b728-817c3a4b2c09');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ld = Library_Dataset(sampledata)"
      ],
      "metadata": {
        "id": "Q6_I4yl8NLSM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Models"
      ],
      "metadata": {
        "id": "VG7IQorfFMIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(load_path, model):# ------ save_checkpoint 함수에서 저장된 모델을 가져오기.\n",
        "    if load_path == None:\n",
        "        return\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    return state_dict['valid_loss']"
      ],
      "metadata": {
        "id": "VYdS0uc_uTJ-"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ML_load_path = \"/content/gdrive/MyDrive/Learned/fullLearn.multiLangModel\"\n",
        "KR_load_path = \"/content/gdrive/MyDrive/Learned/res4.koBertModel\"\n",
        "ID_load_path = \"/content/gdrive/MyDrive/Learned/indexmodel2.multiLangModel\""
      ],
      "metadata": {
        "id": "azgDLIQIPj6x"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "class ML_BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.7):\n",
        "        super(ML_BertClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 11)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        #final_layer = self.relu(linear_output)\n",
        "        return linear_output\n",
        "ML_model = ML_BertClassifier()\n",
        "load_checkpoint(ML_load_path, ML_model)\n",
        "ML_model = ML_model.cuda()"
      ],
      "metadata": {
        "id": "eAG77BLqFKuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6781e465-b4e2-4fa1-f4f9-0557c557631f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from <== /content/gdrive/MyDrive/Learned/fullLearn.multiLangModel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KR_BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=11,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(KR_BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate          \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        else:\n",
        "            out = pooler\n",
        "        return self.classifier(out)\n",
        "\n",
        "dr_rate = 0.7\n",
        "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")\n",
        "KR_model = KR_BERTClassifier(bertmodel, dr_rate=dr_rate)\n",
        "load_checkpoint(KR_load_path, KR_model)\n",
        "KR_model = KR_model.cuda()"
      ],
      "metadata": {
        "id": "7Mh84J2YFogw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d07978-91f4-4d7a-af32-f5e58c7be39e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_v1.zip\n",
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
            "Model loaded from <== /content/gdrive/MyDrive/Learned/res4.koBertModel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Index_BertClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.75):\n",
        "        super(Index_BertClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 11)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, input_id, mask):\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        return linear_output\n",
        "ID_model = Index_BertClassifier()\n",
        "load_checkpoint(ID_load_path,ID_model)\n",
        "ID_model = ID_model.cuda()"
      ],
      "metadata": {
        "id": "pHRuP8cEF1iW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afcd1416-40fa-4b34-ed70-d8fbcaef41de"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from <== /content/gdrive/MyDrive/Learned/indexmodel2.multiLangModel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "class LibraryModel(nn.Module):\n",
        "    def __init__(self, ML_model, KR_model,ID_model):\n",
        "        super(LibraryModel, self).__init__()\n",
        "        self.ML_model = ML_model\n",
        "        self.ID_model = ID_model\n",
        "        self.KR_model = KR_model\n",
        "        self.classifier = nn.Linear(22, 11)\n",
        "        \n",
        "    def forward(self, title, index, lang):\n",
        "        if(lang == 1):\n",
        "            token_ids, valid_length, segment_ids = title\n",
        "            token_ids = token_ids.long().to(device)\n",
        "            segment_ids = segment_ids.long().to(device)\n",
        "            valid_length= valid_length.to(device)\n",
        "            output1 = self.KR_model(token_ids, valid_length, segment_ids)\n",
        "        else: \n",
        "            title_mask = title['attention_mask'].to(device)\n",
        "            title_id = title['input_ids'].squeeze(1).to(device)\n",
        "            output1 = self.ML_model(title_id, title_mask)\n",
        "        index_mask = index['attention_mask'].to(device)\n",
        "        index_id = index['input_ids'].squeeze(1).to(device)\n",
        "        output2 = self.ID_model(index_id, index_mask)\n",
        "        x = torch.cat((output1, output2), dim=1)\n",
        "        x = self.classifier(F.relu(x))\n",
        "        return x\n",
        "Library_model = LibraryModel(ML_model, KR_model,ID_model)\n",
        "'''"
      ],
      "metadata": {
        "id": "sEMNtFMKGUNZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "17e39e95-3305-4d54-d15b-44bac7b85518"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nclass LibraryModel(nn.Module):\\n    def __init__(self, ML_model, KR_model,ID_model):\\n        super(LibraryModel, self).__init__()\\n        self.ML_model = ML_model\\n        self.ID_model = ID_model\\n        self.KR_model = KR_model\\n        self.classifier = nn.Linear(22, 11)\\n        \\n    def forward(self, title, index, lang):\\n        if(lang == 1):\\n            token_ids, valid_length, segment_ids = title\\n            token_ids = token_ids.long().to(device)\\n            segment_ids = segment_ids.long().to(device)\\n            valid_length= valid_length.to(device)\\n            output1 = self.KR_model(token_ids, valid_length, segment_ids)\\n        else: \\n            title_mask = title['attention_mask'].to(device)\\n            title_id = title['input_ids'].squeeze(1).to(device)\\n            output1 = self.ML_model(title_id, title_mask)\\n        index_mask = index['attention_mask'].to(device)\\n        index_id = index['input_ids'].squeeze(1).to(device)\\n        output2 = self.ID_model(index_id, index_mask)\\n        x = torch.cat((output1, output2), dim=1)\\n        x = self.classifier(F.relu(x))\\n        return x\\nLibrary_model = LibraryModel(ML_model, KR_model,ID_model)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 최종 모델"
      ],
      "metadata": {
        "id": "UuQenmNpRbOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "\n",
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "\n",
        "    train, val = Library_Dataset(train_data), Library_Dataset(val_data)\n",
        "    warmup_rate = 0.1\n",
        "    batch_size=1\n",
        "    num_total_steps = (len(df_train) // batch_size) * epochs\n",
        "    num_warmup_steps = num_total_steps * warmup_rate\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True,num_workers=1)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=batch_size)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = AdamW(model.parameters(), lr= learning_rate)\n",
        "    scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
        "                                                         num_warmup_steps=num_warmup_steps, \n",
        "                                                         num_training_steps=num_total_steps)\n",
        "    if use_cuda:\n",
        "            print(\"using cuda!\")\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "            iloss = 0\n",
        "\n",
        "            for i, dataget in enumerate(tqdm(train_dataloader)) :\n",
        "                lang, train_title, train_label, train_index = dataget\n",
        "                train_label = train_label.to(device)\n",
        "                output = model(train_title, train_index, lang)\n",
        "                \n",
        "                batch_loss = criterion(output, train_label.long())\n",
        "                total_loss_train += batch_loss.item()\n",
        "                iloss += batch_loss.item()\n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                if(i%100 == 99):\n",
        "                  print(i//100, \"loss value\", iloss/100);\n",
        "                  iloss =0\n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for val_dataget in val_dataloader:\n",
        "                    val_lang, val_title, val_label, val_index = dataget\n",
        "                    val_label = val_label.to(device)\n",
        "                    output = model(val_title, val_index, val_lang)\n",
        "\n",
        "                    batch_loss = criterion(output, val_label.long())\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "            \n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .4f} \\\n",
        "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "                | Val Loss: {total_loss_val / len(val_data): .4f} \\\n",
        "                | Val Accuracy: {total_acc_val / len(val_data): .3f}') \n",
        "                  \n",
        "EPOCHS = 1\n",
        "model = LibraryModel(ML_model, KR_model,ID_model)\n",
        "LR = 0.0000003          \n",
        "train(model, df_train, df_val, LR, EPOCHS)\n",
        "LB_model = model"
      ],
      "metadata": {
        "id": "4dsN9GUPqCmq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "5f8b02f2-f179-4074-cc17-b1dc70d10c0a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cuda!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 100/2859 [00:28<13:17,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 loss value 2.423138613700867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 200/2859 [00:57<12:54,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loss value 2.4381912726163866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 300/2859 [01:27<12:29,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 loss value 2.3166528183221815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 400/2859 [01:56<11:59,  3.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 loss value 2.282062355875969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 500/2859 [02:25<11:34,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 loss value 2.434919084906578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 600/2859 [02:55<11:02,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 loss value 2.4204973858594894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 700/2859 [03:24<10:29,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 loss value 2.3058427637815475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 800/2859 [03:53<10:04,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 loss value 2.2588672971725465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███▏      | 900/2859 [04:23<09:36,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8 loss value 2.0940098571777344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 1000/2859 [04:52<09:09,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 loss value 2.1729090249538423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 1100/2859 [05:22<08:36,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loss value 2.2204529559612274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 1200/2859 [05:51<08:11,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 loss value 2.2399748873710634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 1300/2859 [06:20<07:39,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 loss value 2.112369762659073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 1400/2859 [06:50<07:09,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13 loss value 2.090431659221649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 1500/2859 [07:19<06:36,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 loss value 1.993153464794159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 1600/2859 [07:48<06:05,  3.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 loss value 2.217773998975754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 1700/2859 [08:18<05:42,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16 loss value 2.0422958725690843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 1800/2859 [08:47<05:11,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17 loss value 2.101896416544914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▋   | 1900/2859 [09:17<04:43,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18 loss value 2.0717538774013518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|██████▉   | 2000/2859 [09:46<04:10,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19 loss value 2.0547488814592363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 2080/2859 [10:10<03:48,  3.41it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-86483422f63e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mML_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKR_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mID_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0000003\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0mLB_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-86483422f63e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             F.adamw(params_with_grad,\n\u001b[0m\u001b[1;32m    138\u001b[0m                     \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def evaluate(model, test_data):\n",
        "    test = Library_Dataset(test_data)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=1)\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "    total_acc_test = 0\n",
        "    with torch.no_grad():\n",
        "        for dataget in tqdm(test_dataloader):\n",
        "            lang, test_title, test_label, test_index = dataget\n",
        "            test_label = test_label.to(device)\n",
        "            output = model(test_title, test_index, lang)\n",
        "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "            total_acc_test += acc  \n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
        "evaluate(model, df_test)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-lrKaZSjhi5",
        "outputId": "7fb7400f-d67c-445b-c629-1b4563d29659"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 358/358 [00:16<00:00, 21.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot8jdXb63ypc"
      },
      "source": [
        "# SAVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "r0gMxnbS3nlb"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(save_path, model, valid_loss):# ------ 모델 평가를 위해 훈련 과정을 저장\n",
        "    if save_path == None:\n",
        "        return\n",
        "    state_dict = {'model_state_dict': model.state_dict(), 'valid_loss': valid_loss}\n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "wtgm7zQ83qo5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd3c4f18-3c9d-435e-c004-ff9ac2605a0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to ==> /content/gdrive/MyDrive/ver1.finalModel\n"
          ]
        }
      ],
      "source": [
        "save_checkpoint(\"/content/gdrive/MyDrive/ver1.finalModel\", model, 1.96)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EMiDp6WiRSq"
      },
      "source": [
        "# TEST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_values(title, index = 0):\n",
        "  #use_cuda = torch.cuda.is_available()\n",
        "  #device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "  #if use_cuda:\n",
        "  #    EN_model = EN_model.cuda()\n",
        "  with torch.no_grad():\n",
        "    if re.fullmatch(regex, title):\n",
        "      transform = nlp.data.BERTSentenceTransform(                                 # 한글용\n",
        "        kr_tok, max_seq_length=64, pad=True, pair=False)\n",
        "      token_ids, valid_length, segment_ids = transform(title)\n",
        "      print(token_ids)\n",
        "      token_ids = token_ids.long().to(device)\n",
        "      segment_ids = segment_ids.long().to(device)\n",
        "      out = KR_model(token_ids, valid_length, segment_ids)\n",
        "      print(\"kr\")\n",
        "    else:\n",
        "      title_data = en_tokenizer(title, padding='max_length', max_length = 64, truncation=True, return_tensors=\"pt\")\n",
        "      input_id = title_data['input_ids']\n",
        "      input_id = input_id.to(device)\n",
        "      mask = title_data['attention_mask']\n",
        "      mask = mask.to(device)\n",
        "      out = ML_model(input_id, mask)\n",
        "      print(\"ml\")\n",
        "    output = F.softmax(out[0],dim=-1)\n",
        "    print(\"max for title: \",torch.topk(output,3))\n",
        "    if(index != 0):\n",
        "      index_data = en_tokenizer(index, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
        "      input_id = index_data['input_ids']\n",
        "      input_id = input_id.to(device)\n",
        "      mask = index_data['attention_mask']\n",
        "      mask = mask.to(device)\n",
        "      out = ID_model(input_id, mask)\n",
        "      output = F.softmax(out[0],dim=-1)\n",
        "      print(\"max for index: \",torch.topk(output,3))\n"
      ],
      "metadata": {
        "id": "C59fTAtEfcaO"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_top_values(\"언어의 심리학\") # 확인해보고 싶은 제목 입력\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "cml4I-5MyOG-",
        "outputId": "ed460cfc-2f7e-45d5-8b4c-8a9f7fbc315a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   2 3241    3    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "    1    1    1    1    1    1    1    1]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-0b2d39d548bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_top_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"언어의 심리학\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 확인해보고 싶은 제목 입력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-e4a4ec7189fd>\u001b[0m in \u001b[0;36mget_top_values\u001b[0;34m(title, index)\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0msegment_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKR_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "golOecY1iNiC"
      },
      "outputs": [],
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "toselftest = [\"테스트1\",\"테스트2\",\"테스트3\"]\n",
        "\n",
        "labels = {0:'총류',\n",
        "          1:'철학',\n",
        "          2:'종교',\n",
        "          3:'사회학',\n",
        "          4:'언어',\n",
        "          5:'자연과학',\n",
        "          6:'기술과학',\n",
        "          7:'경영학',\n",
        "          8:'예술',\n",
        "          9: '문학',\n",
        "          10:'역사'\n",
        "}\n",
        "\n",
        "selftest = DataFrame({\n",
        "  'value': toselftest,\n",
        "  'null': [0 for x in toselftest]\n",
        "})\n",
        "\n",
        "selftest.to_csv(\"/content/gdrive/MyDrive/LibraryCsv/selftest.txt\", sep=\"\\t\")\n",
        "dataset_selftest = nlp.data.TSVDataset(\"/content/gdrive/MyDrive/LibraryCsv/selftest.txt\", field_indices=[1,2], num_discard_samples=1)\n",
        "data_selftest = BERTDataset(dataset_selftest, 0, 1, tok, max_len, True, False)\n",
        "selftest_dataloader = torch.utils.data.DataLoader(data_selftest, batch_size=1, num_workers=1)\n",
        "\n",
        "for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(selftest_dataloader), total=len(selftest_dataloader)):\n",
        "      token_ids = token_ids.long().to(device)\n",
        "      segment_ids = segment_ids.long().to(device)\n",
        "      valid_length= valid_length\n",
        "      label = label.long().to(device)\n",
        "      out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "      prediction = out.cpu().detach().numpy()[0]\n",
        "      minval = prediction.min()\n",
        "      prediction = [x-minval for x in prediction]\n",
        "      sumval = sum(prediction)\n",
        "      print(toselftest[batch_id])\n",
        "      for index, score in sorted(enumerate(prediction), reverse = True, key = lambda prediction:prediction[1]):\n",
        "        print(\"{} {}%\".format(labels[index], score*100/sumval))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "pARbP1JFJ1LI",
        "YsJTAx5FhjhY",
        "t9FlLragKH7C",
        "ITPGlPdMAiB1"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}