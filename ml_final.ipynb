{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diqnfl777/2022F-Ajou-ML-TEAM3/blob/ldhbranch/ml_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pARbP1JFJ1LI"
      },
      "source": [
        "# KoBERT finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P4OehJHMJ1c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7981d8bf-5dee-4bad-86d7-b78fbf1fb30f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (7.9.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (3.0.3)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (3.6.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (5.3.4)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.0.4)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=4.0.0->ipywidgets) (2.0.10)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (1.15.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.8/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (5.7.16)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.1)\n",
            "Requirement already satisfied: jinja2<=3.0.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.15.0)\n",
            "Requirement already satisfied: nbconvert<6.0 in /usr/local/lib/python3.8/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2<=3.0.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.0.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.19.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert<6.0->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-rmsxbzt2\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-rmsxbzt2\n",
            "Collecting boto3<=1.15.18\n",
            "  Downloading boto3-1.15.18-py2.py3-none-any.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting gluonnlp<=0.10.0,>=0.6.0\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 21.4 MB/s \n",
            "\u001b[?25hCollecting mxnet<=1.7.0.post2,>=1.4.0\n",
            "  Downloading mxnet-1.7.0.post2-py2.py3-none-manylinux2014_x86_64.whl (54.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.7 MB 31 kB/s \n",
            "\u001b[?25hCollecting onnxruntime<=1.8.0,==1.8.0\n",
            "  Downloading onnxruntime-1.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 34.8 MB/s \n",
            "\u001b[?25hCollecting sentencepiece<=0.1.96,>=0.1.6\n",
            "  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 49.2 MB/s \n",
            "\u001b[?25hCollecting torch<=1.10.1,>=1.7.0\n",
            "  Downloading torch-1.10.1-cp38-cp38-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.1 MB/s eta 0:00:44tcmalloc: large alloc 1147494400 bytes == 0x3a78a000 @  0x7f98d531b615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x4fdff5 0x49caa1 0x4fdff5 0x49ced5 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x5d7c18 0x5d9412 0x586636 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69 0x5d7c18 0x49ca7c 0x4fdff5 0x49ced5\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 8.4 kB/s \n",
            "\u001b[?25hCollecting transformers<=4.8.1,>=4.8.1\n",
            "  Downloading transformers-4.8.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 107.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.6)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.19.6)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.12)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting botocore<1.19.0,>=1.18.18\n",
            "  Downloading botocore-1.18.18-py2.py3-none-any.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 34.4 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "  Downloading s3transfer-0.3.7-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.32)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (21.3)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.8/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.23.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.1.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 76.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.8.0)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.6.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 79.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (3.0.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.2.0)\n",
            "Building wheels for collected packages: kobert, gluonnlp, sacremoses\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15708 sha256=e66d02657c3cff8cd2cccfecfbced6403db28172beddabb46d52cb83ed6eb4a5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6py8a7d5/wheels/bf/5f/74/81bf3a1332130eb6629ecf58876a8746b77021e7d7b0638e91\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp38-cp38-linux_x86_64.whl size=619640 sha256=6de4dddf83aa377cd709de5dca0b3fa19f374c6147354fca7294b9c16c461ffc\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/93/9d/2237550c409eb3ed725d6302b7897ddd9a037b40cef66dcd9c\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=9cf7a3c2146b2ebdfed5ffaf4c1c6a34c151fcaea2290fbe37982804224812f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built kobert gluonnlp sacremoses\n",
            "Installing collected packages: jmespath, botocore, tokenizers, sacremoses, s3transfer, huggingface-hub, graphviz, transformers, torch, sentencepiece, onnxruntime, mxnet, gluonnlp, boto3, kobert\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.10.1 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.15.18 botocore-1.18.18 gluonnlp-0.10.0 graphviz-0.8.4 huggingface-hub-0.0.12 jmespath-0.10.0 kobert-0.2.3 mxnet-1.7.0.post2 onnxruntime-1.8.0 s3transfer-0.3.7 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.10.3 torch-1.10.1 transformers-4.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ipywidgets  # for vscode\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6Vn5bcTOJ1dD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SQ7nWEFdJ1dF"
      },
      "outputs": [],
      "source": [
        "from kobert import get_tokenizer\n",
        "from kobert import get_pytorch_kobert_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TPZqVOEgJ1dJ"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jSnu1VOCJ1dQ"
      },
      "outputs": [],
      "source": [
        "## CPU\n",
        "# device = torch.device(\"cpu\")\n",
        "\n",
        "## GPU\n",
        "device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-D3gwc-GJ1dS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b92d888c-3da6-47cc-8c97-e8cdd6e8b254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/.cache/kobert_v1.zip[██████████████████████████████████████████████████]\n",
            "/content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]\n"
          ]
        }
      ],
      "source": [
        "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_BBFVZw62c-"
      },
      "source": [
        "# KOR PARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xKg_RyV1J1xj"
      },
      "outputs": [],
      "source": [
        "## Setting parameters\n",
        "max_len = 64\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 5\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5\n",
        "\n",
        "frac = 1\n",
        "test_size = 0.2\n",
        "dr_rate = 0.7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9FlLragKH7C"
      },
      "source": [
        "# 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lEcih63FJ1dW"
      },
      "outputs": [],
      "source": [
        "# !wget -O .cache/ratings_train.txt http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_train.txt\n",
        "# !wget -O .cache/ratings_test.txt http://skt-lsl-nlp-model.s3.amazonaws.com/KoBERT/datasets/nsmc/ratings_test.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V1LxkUfVJ1dg"
      },
      "outputs": [],
      "source": [
        "# dataset_train = nlp.data.TSVDataset(\".cache/ratings_train.txt\", field_indices=[1,2], num_discard_samples=1)\n",
        "# dataset_test = nlp.data.TSVDataset(\".cache/ratings_test.txt\", field_indices=[1,2], num_discard_samples=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EpXK3nnOrDy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7206ebf7-9711-4416-9b13-3d3e5ef3c54e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "B-ibCF9LKVVj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9e8d134b-7598-479c-d310-c517018647b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 제목  청구번호\n",
              "1       대학수학능력시험의 영어 독해문제 분석 및 개선방안     0\n",
              "5                           위험한 생각들     0\n",
              "34                           무지의 사전     0\n",
              "38              21세기 지구에 등장한 새로운 지식     0\n",
              "42                             두 문화     0\n",
              "...                             ...   ...\n",
              "436189                         독도연감    10\n",
              "436250                      중국현대사사전    10\n",
              "436276                       이슬람 사전    10\n",
              "436281                      싱가포르 편람    10\n",
              "436308                         칠레편람    10\n",
              "\n",
              "[91245 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d88cbee0-f1b5-4131-b70b-0b1119e1c138\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>제목</th>\n",
              "      <th>청구번호</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>대학수학능력시험의 영어 독해문제 분석 및 개선방안</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>위험한 생각들</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>무지의 사전</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>21세기 지구에 등장한 새로운 지식</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>두 문화</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436189</th>\n",
              "      <td>독도연감</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436250</th>\n",
              "      <td>중국현대사사전</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436276</th>\n",
              "      <td>이슬람 사전</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436281</th>\n",
              "      <td>싱가포르 편람</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436308</th>\n",
              "      <td>칠레편람</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91245 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d88cbee0-f1b5-4131-b70b-0b1119e1c138')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d88cbee0-f1b5-4131-b70b-0b1119e1c138 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d88cbee0-f1b5-4131-b70b-0b1119e1c138');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#데이터 가공\n",
        "#청구기호 숫자 앞 2개만 따와서 각각 매핑. 65~70은 예외적으로 경영학\n",
        "import pandas as pd\n",
        "import re \n",
        "data = pd.read_csv(\"/content/gdrive/MyDrive/LibraryCsv/hapbon.csv\", encoding = \"cp949\")\n",
        "data = data.loc[:,['제목', '청구번호']]\n",
        "data['청구번호'] = data['청구번호'].apply(str)\n",
        "\n",
        "data['청구번호'] = data['청구번호'].replace({r'(.*?)(\\d{2})\\d.*' : r'\\2'}, regex=True)\n",
        "\n",
        "data['청구번호'] = pd.to_numeric(data['청구번호'])\n",
        "data.loc[(data['청구번호'] < 10), ['청구번호']] = 1000\n",
        "data.loc[(data['청구번호'] < 20), ['청구번호']] = 1001\n",
        "data.loc[(data['청구번호'] < 30), ['청구번호']] = 1002\n",
        "data.loc[(data['청구번호'] < 40), ['청구번호']] = 1003\n",
        "data.loc[(data['청구번호'] < 50), ['청구번호']] = 1004\n",
        "data.loc[(data['청구번호'] < 60), ['청구번호']] = 1005\n",
        "data.loc[(data['청구번호'] < 65), ['청구번호']] = 1006 #경영학쪽은 따로 분류이기 떄문에 65 사용\n",
        "data.loc[(data['청구번호'] < 70), ['청구번호']] = 1007 #즉, 1007 쪽이 경영학책\n",
        "data.loc[(data['청구번호'] < 80), ['청구번호']] = 1008\n",
        "data.loc[(data['청구번호'] < 90), ['청구번호']] = 1009\n",
        "data.loc[(data['청구번호'] <  100), ['청구번호']] = 1010\n",
        "\n",
        "labels = {'0':'총류',\n",
        "          '1':'철학',\n",
        "          '2':'종교',\n",
        "          '3':'사회학',\n",
        "          '4':'언어',\n",
        "          '5':'자연과학',\n",
        "          '6':'기술과학',\n",
        "          '7':'경영학',\n",
        "          '8':'예술',\n",
        "          '9':'문학',\n",
        "          '10':'역사'\n",
        "          }\n",
        "\n",
        "data['청구번호'] = data['청구번호']%1000\n",
        "data['청구번호'] = data['청구번호'].astype(int)\n",
        "# data['청구번호'] = data['청구번호'].apply(str)\n",
        "# data['청구번호'] = data['청구번호'].replace(labels)\n",
        "\n",
        "#input_string = \"Peace-building and development in Guatemala and Northern Ireland\"\n",
        "regex = '[0-9|A-Z|a-z|ㄱ-ㅎ|ㅏ-ㅣ|가-힣|\\s]*[ㄱ-ㅎ|ㅏ-ㅣ|가-힣][0-9|A-Z|a-z|ㄱ-ㅎ|ㅏ-ㅣ|가-힣|\\s]*'\n",
        "kor_data = data[data.제목.str.fullmatch(regex)]                                 # 한글이 있다면 따로 빼내기\n",
        "eng_data = pd.concat([data, kor_data, kor_data]).drop_duplicates(keep=False)\n",
        "\n",
        "kor_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# en_labels = {'0':'totals',\n",
        "#            '1':'philosophy',\n",
        "#            '2':'religion',\n",
        "#            '3':'sociology',\n",
        "#            '4':'language',\n",
        "#            '5':'Natural science',\n",
        "#            '6':'Technology',\n",
        "#            '7':'Business Administration',\n",
        "#            '8':'art',\n",
        "#            '9':'literature',\n",
        "#            '10': 'history'\n",
        "#            }\n",
        "\n",
        "# sum1 = 0\n",
        "# sum2 = 0\n",
        "# for i in range(0,11):\n",
        "#   nameparsed = data[data['제목'].str.contains(labels[str(i)])]\n",
        "#   namecount = len(nameparsed)\n",
        "#   numberparsed = nameparsed[nameparsed['청구번호']==i]\n",
        "#   numbercount = len(numberparsed)\n",
        "#   print(labels[str(i)], namecount, numbercount, numbercount*100/namecount)\n",
        "#   # print(nameparsed)\n",
        "#   sum1 += namecount\n",
        "#   sum2 += numbercount\n",
        "\n",
        "# print(sum1)\n",
        "# print(sum2)\n",
        "# print(sum2*100/sum1)"
      ],
      "metadata": {
        "id": "BIhhncUEaXDr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eng_data['청구번호'].value_counts(sort=False)"
      ],
      "metadata": {
        "id": "MCwTjXU8yWbo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HbEzvjX6b5PI"
      },
      "outputs": [],
      "source": [
        "kor_data = kor_data.sample(frac = frac, random_state = 1)\n",
        "# kor_data.to_csv(\"/content/gdrive/MyDrive/LibraryCsv/hapbonkordata.txt\", sep=\"\\t\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(kor_data, test_size=test_size, stratify = kor_data['청구번호'])\n",
        "train.to_csv(\"/content/gdrive/MyDrive/LibraryCsv/train.txt\", sep=\"\\t\")\n",
        "test.to_csv(\"/content/gdrive/MyDrive/LibraryCsv/test.txt\", sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CLgX0DnlsOwi"
      },
      "outputs": [],
      "source": [
        "dataset_train = nlp.data.TSVDataset(\"/content/gdrive/MyDrive/LibraryCsv/train.txt\", field_indices=[1,2], num_discard_samples=1)\n",
        "dataset_test = nlp.data.TSVDataset(\"/content/gdrive/MyDrive/LibraryCsv/test.txt\", field_indices=[1,2], num_discard_samples=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwQMfnu03udr"
      },
      "source": [
        "# KOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BVrzP93lJ1dx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d7c56a-aaf8-44ec-c11a-a5daf72e6b63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ],
      "source": [
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FT0wZOrzJ1dz"
      },
      "outputs": [],
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bZ-1tyo5J1xy"
      },
      "outputs": [],
      "source": [
        "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MVE7hPPMJ1x0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72804cc2-415d-468a-f070-a071a3e7140a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "OJePC7kJJ1x4"
      },
      "outputs": [],
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=11,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        else:\n",
        "            out = pooler\n",
        "        return self.classifier(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "N2Vi7DloJ1x6"
      },
      "outputs": [],
      "source": [
        "model = BERTClassifier(bertmodel, dr_rate=dr_rate).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5eRQpqF7J1x7"
      },
      "outputs": [],
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DFsM4x_XJ1x8"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "H33A4tzaJ1x-"
      },
      "outputs": [],
      "source": [
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Glr7r-dJJ1yA"
      },
      "outputs": [],
      "source": [
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "l71y4IbEJ1yA"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OplqwK-NJ1yD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b94c93b8beec48c194865c94d465fec9",
            "4e9f7a3c744f4b7abd48ea6c472155c1",
            "60da93ce4faa4991ac85514460d7fa2d",
            "15857349ecc44fd68527ecf4f779f984",
            "5813dc7905a947bbb2dd468783c952bd",
            "c1d9c9181b92469fb791353760607965",
            "69621886ad8b4ffd8bddae3b66eccc35",
            "6724886aea67497abab927b4f8740e44",
            "b3ab92da9e3c483eb35680f6b45ed897",
            "f5ddea227ca745e696ded7e3562cb43c",
            "6a4fdaf0bd5e4348a191fc30fe95afd8"
          ]
        },
        "outputId": "4d0daf77-2816-41b2-c5b7-4dbf376e6306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1141 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b94c93b8beec48c194865c94d465fec9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 6,  7, 10,  8, 11,  7,  5, 12,  8, 11, 11,  7,  7, 11, 11, 10, 10,  3,\n",
            "         8,  7,  9, 13,  6,  9,  8, 12,  8, 13,  6, 13,  4,  4,  9,  6,  7,  7,\n",
            "         7,  5,  6,  4,  8,  6,  9, 15,  9,  5,  6,  6, 12,  4,  6,  7,  6,  6,\n",
            "        11,  3,  8,  6,  7,  7, 11,  9, 11,  4], dtype=torch.int32)\n",
            "tensor([ 6,  7, 10,  8, 11,  7,  5, 12,  8, 11, 11,  7,  7, 11, 11, 10, 10,  3,\n",
            "         8,  7,  9, 13,  6,  9,  8, 12,  8, 13,  6, 13,  4,  4,  9,  6,  7,  7,\n",
            "         7,  5,  6,  4,  8,  6,  9, 15,  9,  5,  6,  6, 12,  4,  6,  7,  6,  6,\n",
            "        11,  3,  8,  6,  7,  7, 11,  9, 11,  4], dtype=torch.int32)\n",
            "epoch 1 batch id 1 loss 2.4858133792877197 train acc 0.0625\n",
            "tensor([ 3,  6,  7, 10, 10,  9, 10, 13,  9, 16,  9,  6, 10,  8,  5, 15, 11,  6,\n",
            "         7, 10, 14,  7, 10,  4,  7,  8, 13,  6,  7,  6,  8,  8,  8,  4,  9,  9,\n",
            "         8,  7,  9, 13,  8,  5,  6, 11,  8,  7, 16,  8,  5,  5,  5, 10,  8,  8,\n",
            "        11,  6,  7,  4,  7,  6,  9, 12,  6,  7], dtype=torch.int32)\n",
            "tensor([ 3,  6,  7, 10, 10,  9, 10, 13,  9, 16,  9,  6, 10,  8,  5, 15, 11,  6,\n",
            "         7, 10, 14,  7, 10,  4,  7,  8, 13,  6,  7,  6,  8,  8,  8,  4,  9,  9,\n",
            "         8,  7,  9, 13,  8,  5,  6, 11,  8,  7, 16,  8,  5,  5,  5, 10,  8,  8,\n",
            "        11,  6,  7,  4,  7,  6,  9, 12,  6,  7], dtype=torch.int32)\n",
            "tensor([ 6,  9,  6, 16,  8, 14, 11,  8, 12, 16, 12, 12,  7,  6,  9, 10,  8,  7,\n",
            "         5,  5, 19,  9, 10,  7,  9, 12,  7, 12,  6,  9,  6,  3, 15, 10,  6,  7,\n",
            "         6,  5, 11,  5,  8,  8,  5, 10,  7, 14,  9,  9,  9,  6, 11,  5,  8,  8,\n",
            "         9,  8,  7,  6, 11,  7, 10, 11,  7,  6], dtype=torch.int32)\n",
            "tensor([ 6,  9,  6, 16,  8, 14, 11,  8, 12, 16, 12, 12,  7,  6,  9, 10,  8,  7,\n",
            "         5,  5, 19,  9, 10,  7,  9, 12,  7, 12,  6,  9,  6,  3, 15, 10,  6,  7,\n",
            "         6,  5, 11,  5,  8,  8,  5, 10,  7, 14,  9,  9,  9,  6, 11,  5,  8,  8,\n",
            "         9,  8,  7,  6, 11,  7, 10, 11,  7,  6], dtype=torch.int32)\n",
            "tensor([ 8,  7,  6, 14,  8, 12,  8, 12,  9,  5, 10, 13,  4,  7,  6,  8,  8,  7,\n",
            "        12,  4, 19, 10,  7,  7,  7,  8,  8,  9,  9,  8, 14, 19, 11, 11,  8,  5,\n",
            "         7,  6,  6,  8,  7,  9,  8,  8,  8,  6, 14,  7, 16,  5, 11,  8,  4,  8,\n",
            "        11,  5,  7,  5,  6, 13,  6, 11,  6,  8], dtype=torch.int32)\n",
            "tensor([ 8,  7,  6, 14,  8, 12,  8, 12,  9,  5, 10, 13,  4,  7,  6,  8,  8,  7,\n",
            "        12,  4, 19, 10,  7,  7,  7,  8,  8,  9,  9,  8, 14, 19, 11, 11,  8,  5,\n",
            "         7,  6,  6,  8,  7,  9,  8,  8,  8,  6, 14,  7, 16,  5, 11,  8,  4,  8,\n",
            "        11,  5,  7,  5,  6, 13,  6, 11,  6,  8], dtype=torch.int32)\n",
            "tensor([ 7,  7,  9,  4,  8,  7,  6,  8,  9,  6,  8, 10,  9,  8,  8,  6, 10, 10,\n",
            "         6, 14,  4,  7, 13,  7,  5,  3, 10,  9, 10,  9,  5,  5, 18,  9, 16,  7,\n",
            "         5,  5,  7,  6,  6,  6,  9, 11,  8,  7, 14,  8,  7,  8,  6,  7,  7,  9,\n",
            "        11,  4,  7,  4, 14, 16, 10,  8,  8,  8], dtype=torch.int32)\n",
            "tensor([ 7,  7,  9,  4,  8,  7,  6,  8,  9,  6,  8, 10,  9,  8,  8,  6, 10, 10,\n",
            "         6, 14,  4,  7, 13,  7,  5,  3, 10,  9, 10,  9,  5,  5, 18,  9, 16,  7,\n",
            "         5,  5,  7,  6,  6,  6,  9, 11,  8,  7, 14,  8,  7,  8,  6,  7,  7,  9,\n",
            "        11,  4,  7,  4, 14, 16, 10,  8,  8,  8], dtype=torch.int32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f4f12112c593>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot8jdXb63ypc"
      },
      "source": [
        "# SAVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "r0gMxnbS3nlb"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(save_path, model, valid_loss):# ------ 모델 평가를 위해 훈련 과정을 저장\n",
        "    if save_path == None:\n",
        "        return\n",
        "    state_dict = {'model_state_dict': model.state_dict(), 'valid_loss': valid_loss}\n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_checkpoint(load_path, model):# ------ save_checkpoint 함수에서 저장된 모델을 가져옵니다.\n",
        "    if load_path == None:\n",
        "        return\n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    return state_dict['valid_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtgm7zQ83qo5"
      },
      "outputs": [],
      "source": [
        "save_checkpoint(\"/content/gdrive/MyDrive/learned.multiLangModel\", model, 0.325)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EMiDp6WiRSq"
      },
      "source": [
        "# TEST"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_checkpoint(\"/content/gdrive/MyDrive/final.koBertModel\", model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJSi_hBPoEiG",
        "outputId": "c54f2103-7837-43d0-a38b-a097cd15373a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from <== /content/gdrive/MyDrive/final.koBertModel\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.325"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "golOecY1iNiC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4930f1e45516485baffc9c970d0bd4c1",
            "1669351db5cb489c9c5ec3f56077627d",
            "3355b8221c5b49bc8e7266a43de9a1e2",
            "22f223c2a6c9440ca76cb8ec276ad2d0",
            "40ccf7024f0d4ca2a7516757335e2162",
            "b194d80ec288429196a867b6b3c20428",
            "fbe6b9028ff94dbe8d050fa35072a2ed",
            "bc1be9a3b5c34c9babab176a9913c8de",
            "93f5a725217e49bb829f0df47ada296e",
            "fd3ea090a87545cb9a80147780c7a6d4",
            "799a03e5b04b4b29af262467458d6cdb"
          ]
        },
        "outputId": "d7bbc9aa-cb69-4fb5-deab-1937e6a52f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18249\n",
            "18249\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/18249 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4930f1e45516485baffc9c970d0bd4c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7006, 0.1869, 0.0320], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 3, 6], device='cuda:0'))\n",
            "트렌드 => 경영학\n",
            "경영학 20.20837774787995%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9347, 0.0370, 0.0082], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 6, 5], device='cuda:0'))\n",
            "청소년을 위한 성교육 => 사회학\n",
            "사회학 28.67881846202919%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9672, 0.0210, 0.0034], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([6, 5, 7], device='cuda:0'))\n",
            "물리전자공학 => 기술과학\n",
            "기술과학 37.62482417487468%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7856, 0.1552, 0.0209], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  8], device='cuda:0'))\n",
            "쿠데타와 공화정 => 사회학\n",
            "사회학 23.81691613023647%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9176, 0.0396, 0.0159], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 6,  3, 10], device='cuda:0'))\n",
            "서양요리 => 기술과학\n",
            "기술과학 29.709976191273554%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9822, 0.0057, 0.0029], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 5,  2, 10], device='cuda:0'))\n",
            "숨겨진 과학의 역사 => 자연과학\n",
            "자연과학 38.507360814009964%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8730, 0.0938, 0.0198], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  9,  8], device='cuda:0'))\n",
            "알프스 힐링캠프 => 역사\n",
            "역사 25.13445397612932%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9721, 0.0042, 0.0037], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([4, 0, 5], device='cuda:0'))\n",
            "한국어 학습자 말뭉치와 오류 분석 => 언어\n",
            "언어 62.78330522920325%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9699e-01, 8.5050e-04, 4.8582e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 0, 1], device='cuda:0'))\n",
            "사회학사전 => 사회학\n",
            "사회학 44.82600866386985%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.4744, 0.2140, 0.1052], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 8, 3], device='cuda:0'))\n",
            "컴퓨터 게임 => 예술\n",
            "문학 17.990422323321212%\n",
            "예술 15.713281836302517%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9531e-01, 1.5879e-03, 6.8733e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  0], device='cuda:0'))\n",
            "각국의 평생교육정책 => 사회학\n",
            "사회학 52.664859019164766%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9645, 0.0078, 0.0055], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 6, 10,  3], device='cuda:0'))\n",
            "해외 여행 가서 꼭 먹어야 할 음식 130가지 => 기술과학\n",
            "기술과학 28.536765550601846%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9525, 0.0365, 0.0021], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 8, 4], device='cuda:0'))\n",
            "어둠의 시간 => 문학\n",
            "문학 44.37468434050002%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.4272, 0.2815, 0.1796], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 6, 1], device='cuda:0'))\n",
            "비정근 => 문학\n",
            "문학 22.975256118542735%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9196, 0.0223, 0.0146], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 3, 2], device='cuda:0'))\n",
            "사랑이 나를 다시 살게 했습니다 => 문학\n",
            "문학 32.36201328028518%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8104, 0.1447, 0.0218], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 3, 9], device='cuda:0'))\n",
            "37세 MBA 도전 => 문학\n",
            "경영학 28.544076698560634%\n",
            "사회학 21.6224224249955%\n",
            "문학 14.01690839430609%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.8735e-01, 9.1212e-03, 7.9644e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  1], device='cuda:0'))\n",
            "일본의 지방분권과 주민 자치 => 사회학\n",
            "사회학 38.518046381569405%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9405e-01, 2.2257e-03, 8.4337e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  7], device='cuda:0'))\n",
            "중앙아시아의 부상과 한국의 대응전략 => 사회학\n",
            "사회학 41.01257361745082%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9422, 0.0190, 0.0119], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 8, 10,  0], device='cuda:0'))\n",
            "샤갈 => 예술\n",
            "예술 27.802770663028184%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8592, 0.1115, 0.0133], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 3, 9], device='cuda:0'))\n",
            "대기업 고시를 잡아라 => 경영학\n",
            "경영학 31.37677216975187%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9655, 0.0085, 0.0073], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 7, 1], device='cuda:0'))\n",
            "뉴미디어 시대가 오고 있다 => 사회학\n",
            "사회학 29.55123940100611%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9757, 0.0114, 0.0028], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 7, 6], device='cuda:0'))\n",
            "지역별 총요소생산성 분석 => 사회학\n",
            "사회학 38.96690615233679%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9741e-01, 8.1047e-04, 2.6909e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 3, 6], device='cuda:0'))\n",
            "정부 및 비영리조직의 회계 => 경영학\n",
            "경영학 54.81962181174604%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8076, 0.1531, 0.0085], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([1, 3, 2], device='cuda:0'))\n",
            "사회윤리 이론과 도덕교육 => 철학\n",
            "철학 32.05425274899788%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9863, 0.0083, 0.0030], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 7, 6], device='cuda:0'))\n",
            "철강재 물가변화의 주요 생산자 물가지수에 대한 영향 분석 => 사회학\n",
            "사회학 41.38867475751218%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9361, 0.0232, 0.0079], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([8, 6, 0], device='cuda:0'))\n",
            "머리가 좋아지는 아이들 방 꾸미기 => 예술\n",
            "예술 48.543876381432156%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9859, 0.0051, 0.0021], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  1], device='cuda:0'))\n",
            "사회경제사 => 사회학\n",
            "사회학 36.018030505941965%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9885, 0.0037, 0.0025], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9, 10,  2], device='cuda:0'))\n",
            "인도방랑 => 문학\n",
            "문학 37.16924974692032%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8582, 0.0652, 0.0581], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([6, 0, 3], device='cuda:0'))\n",
            "방송통신기자재 위해 맵 및 추적관리시스템 구축체계 방안마련 연구 => 기술과학\n",
            "기술과학 25.64709941362644%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9368, 0.0439, 0.0055], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([6, 3, 0], device='cuda:0'))\n",
            "개인휴대통신과 21세기 위성통신 => 기술과학\n",
            "기술과학 35.87906181995523%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.6547, 0.2076, 0.0558], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 7, 6], device='cuda:0'))\n",
            "커피가 식기 전에 => 문학\n",
            "문학 25.6999310189713%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.6066, 0.1647, 0.1355], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([5, 1, 9], device='cuda:0'))\n",
            "시간여행 => 문학\n",
            "자연과학 26.815845345465753%\n",
            "철학 19.676979490771163%\n",
            "문학 18.60871247062304%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9293, 0.0298, 0.0241], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 1, 8], device='cuda:0'))\n",
            "현대사회와 여가 => 사회학\n",
            "사회학 26.070604573855206%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9443, 0.0125, 0.0097], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([1, 2, 0], device='cuda:0'))\n",
            "꿈의 해석 => 철학\n",
            "철학 43.97543041220809%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9847, 0.0036, 0.0022], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 0, 4], device='cuda:0'))\n",
            "한국전후소설연구 => 문학\n",
            "문학 44.243783021786584%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9490, 0.0289, 0.0147], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  6], device='cuda:0'))\n",
            "한국해양사 => 사회학\n",
            "사회학 35.27290607894677%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7005, 0.2492, 0.0126], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([1, 9, 2], device='cuda:0'))\n",
            "사랑과 죽음의 팡세 => 종교\n",
            "철학 27.82276266867833%\n",
            "문학 23.309225028561038%\n",
            "종교 10.267895162866239%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9679, 0.0145, 0.0061], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9,  2, 10], device='cuda:0'))\n",
            "님의 침묵 => 문학\n",
            "문학 34.11787912527632%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9945, 0.0011, 0.0010], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 1, 8], device='cuda:0'))\n",
            "회계학원론 => 경영학\n",
            "경영학 51.108737533726284%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7126, 0.2192, 0.0401], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([1, 9, 2], device='cuda:0'))\n",
            "하루 한번의 사색 => 철학\n",
            "철학 32.7649118704434%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9914, 0.0023, 0.0015], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([4, 9, 3], device='cuda:0'))\n",
            "방송언어 순화자료집 => 언어\n",
            "언어 46.68821203472772%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9721e-01, 6.7295e-04, 4.8571e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3,  1, 10], device='cuda:0'))\n",
            "노동사회학 => 사회학\n",
            "사회학 43.733608849845524%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9053, 0.0495, 0.0120], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 1,  9, 10], device='cuda:0'))\n",
            "나의 철학 유언 => 철학\n",
            "철학 28.063084387435847%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7172, 0.2103, 0.0181], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 1, 3], device='cuda:0'))\n",
            "성인용 직업적성검사 개정연구 최종보고서 => 경영학\n",
            "경영학 32.80266026792387%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9663, 0.0127, 0.0072], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9,  0, 10], device='cuda:0'))\n",
            "수필의 해석 => 문학\n",
            "문학 32.25706708064698%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9884, 0.0047, 0.0014], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 8, 3], device='cuda:0'))\n",
            "야쿠비얀 빌딩 => 문학\n",
            "문학 39.922276610002015%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8045, 0.1365, 0.0364], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([8, 7, 6], device='cuda:0'))\n",
            "주택기술 동의어집 => 경영학\n",
            "예술 33.2602287585736%\n",
            "경영학 24.142674916217338%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9643e-01, 1.4005e-03, 4.8287e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  1], device='cuda:0'))\n",
            "한국의 선거정치학 => 사회학\n",
            "사회학 47.779457533979325%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9750, 0.0069, 0.0049], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9, 10,  8], device='cuda:0'))\n",
            "스파르타쿠스 => 문학\n",
            "문학 36.12066038896852%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9635e-01, 1.1009e-03, 7.9900e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3,  7, 10], device='cuda:0'))\n",
            "일자리 창출을 위한 지역개발정책의 혁신방안 => 사회학\n",
            "사회학 39.61318106261395%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9559, 0.0238, 0.0103], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  9,  3], device='cuda:0'))\n",
            "잊혀진 이집트를 찾아서 => 역사\n",
            "역사 27.05389546721317%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9599, 0.0260, 0.0059], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9, 10,  3], device='cuda:0'))\n",
            "통하면 통한다 => 문학\n",
            "문학 39.15684522772307%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9871, 0.0040, 0.0027], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  0], device='cuda:0'))\n",
            "세계최종전쟁론 => 사회학\n",
            "사회학 31.830980805022353%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9860, 0.0034, 0.0023], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9,  8, 10], device='cuda:0'))\n",
            "계절 산문 => 문학\n",
            "문학 46.67714256324499%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.6206, 0.3159, 0.0372], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  0,  3], device='cuda:0'))\n",
            "한국학생운동관련 문헌해제 => 사회학\n",
            "역사 29.14714683431656%\n",
            "총류 25.97598461891716%\n",
            "사회학 15.933353194766774%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7120, 0.1210, 0.1057], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 1, 3], device='cuda:0'))\n",
            "우리에겐 서로가 필요하다 => 문학\n",
            "문학 24.99970036609595%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9822, 0.0049, 0.0029], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9,  0, 10], device='cuda:0'))\n",
            "딱지본 대중소설의 발견 => 문학\n",
            "문학 46.91595589074371%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9942, 0.0013, 0.0011], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([0, 6, 8], device='cuda:0'))\n",
            "PC Tools 사용법 => 총류\n",
            "총류 56.02843287289566%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9475, 0.0180, 0.0179], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  9,  3], device='cuda:0'))\n",
            "선비문화 => 역사\n",
            "역사 38.90433586531313%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7769, 0.1459, 0.0189], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 8, 7], device='cuda:0'))\n",
            "스피치 나침반 => 문학\n",
            "문학 25.74556151476275%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9051, 0.0385, 0.0301], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 6, 2], device='cuda:0'))\n",
            "죽은 자의 집 청소 => 문학\n",
            "문학 24.87877004945364%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9885, 0.0032, 0.0023], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 6, 8], device='cuda:0'))\n",
            "도시토지경제학 => 사회학\n",
            "사회학 39.837241914035225%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.5794, 0.3615, 0.0175], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([0, 9, 1], device='cuda:0'))\n",
            "고전읽기의 즐거움 => 문학\n",
            "총류 29.173611640527266%\n",
            "문학 26.729802030786452%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9888, 0.0049, 0.0024], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  1], device='cuda:0'))\n",
            "한국과 국제정치 => 사회학\n",
            "사회학 40.320790079092546%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9746, 0.0101, 0.0040], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 0, 6], device='cuda:0'))\n",
            "절대로 안 망하는 쇼핑몰 만들기 => 경영학\n",
            "경영학 35.03412255940084%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9899, 0.0032, 0.0012], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 0, 8], device='cuda:0'))\n",
            "사회복지 대백과 사전 => 사회학\n",
            "사회학 49.673019787404215%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9473, 0.0185, 0.0137], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([0, 3, 4], device='cuda:0'))\n",
            "대학생활과 정보활용 => 총류\n",
            "총류 31.445746513474102%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.5826, 0.3406, 0.0251], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 2, 1], device='cuda:0'))\n",
            "흐르는 물처럼 나는 새처럼 => 예술\n",
            "문학 25.017554114134022%\n",
            "종교 22.76324372790507%\n",
            "철학 11.810213284294884%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9546, 0.0158, 0.0119], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 3, 6], device='cuda:0'))\n",
            "기술경영전략 길라잡이 => 경영학\n",
            "경영학 37.31143213751293%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8706, 0.0647, 0.0194], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 3, 7], device='cuda:0'))\n",
            "그래도 언니는 간다 => 문학\n",
            "문학 26.824889430037604%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9765, 0.0067, 0.0058], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 3, 1], device='cuda:0'))\n",
            "고객 경험 혁신을 위한 서비스 디자인 특강 => 경영학\n",
            "경영학 42.36019376853996%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9745, 0.0040, 0.0039], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([6, 3, 9], device='cuda:0'))\n",
            "가정한방진료실 => 기술과학\n",
            "기술과학 33.90344361506991%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9303e-01, 1.3511e-03, 9.4479e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  6], device='cuda:0'))\n",
            "상호직결운행을 고려한 철도망 확충과 노선개편 패러다임 구상 => 사회학\n",
            "사회학 39.10205300448257%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9877, 0.0041, 0.0020], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 8, 1], device='cuda:0'))\n",
            "시린 발 => 문학\n",
            "문학 33.62536430404361%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9235, 0.0322, 0.0310], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  9,  8], device='cuda:0'))\n",
            "드골 II => 역사\n",
            "역사 29.919215509371796%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9770, 0.0063, 0.0038], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 1, 2], device='cuda:0'))\n",
            "세상을 껴안다 => 문학\n",
            "문학 39.012685454603535%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9638, 0.0096, 0.0079], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 3, 9], device='cuda:0'))\n",
            "이런 관리자는 내일이 두렵다 => 경영학\n",
            "경영학 44.64759841036178%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9064, 0.0683, 0.0069], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9, 10,  8], device='cuda:0'))\n",
            "글밭을 일구는 사람들 => 문학\n",
            "문학 29.992499876240775%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9890, 0.0034, 0.0030], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  9,  3], device='cuda:0'))\n",
            "백제의 민속 => 역사\n",
            "역사 41.995233817955416%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9925, 0.0014, 0.0010], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 1, 6], device='cuda:0'))\n",
            "상법 핵심 암기장 => 사회학\n",
            "사회학 41.80731959425945%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9767, 0.0068, 0.0056], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 2, 8], device='cuda:0'))\n",
            "비둘기는 집으로 돌아온다 => 문학\n",
            "문학 39.9051346844775%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9769, 0.0089, 0.0031], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([8, 7, 6], device='cuda:0'))\n",
            "로스트 페인팅 => 예술\n",
            "예술 35.63880422123103%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9561, 0.0281, 0.0039], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([5, 6, 4], device='cuda:0'))\n",
            "대기과학 => 자연과학\n",
            "자연과학 47.83407845644452%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9693, 0.0147, 0.0075], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 6, 8], device='cuda:0'))\n",
            "건축환경공학 => 경영학\n",
            "경영학 29.856633281064163%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9826, 0.0048, 0.0032], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 5,  6, 10], device='cuda:0'))\n",
            "측량학 서브노트 => 자연과학\n",
            "자연과학 33.10892739855157%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9033, 0.0406, 0.0293], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  3,  9], device='cuda:0'))\n",
            "한국인의 죽음과 사십구재 => 사회학\n",
            "역사 27.943449606812504%\n",
            "사회학 16.681175972962766%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.6622, 0.1999, 0.0583], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 9, 1], device='cuda:0'))\n",
            "문화사회를 위하여 => 사회학\n",
            "사회학 22.590924638754874%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9822, 0.0047, 0.0026], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([0, 7, 3], device='cuda:0'))\n",
            "웹 데이터베이스 프라이머 플러스 => 총류\n",
            "총류 51.409212913102564%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8325, 0.1358, 0.0239], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([6, 7, 5], device='cuda:0'))\n",
            "공업 열역학 => 기술과학\n",
            "기술과학 36.010492931561146%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9900, 0.0029, 0.0017], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9, 10,  8], device='cuda:0'))\n",
            "파란 눈 검은 머리 => 문학\n",
            "문학 42.85469810417145%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9788, 0.0144, 0.0026], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 7, 6], device='cuda:0'))\n",
            "리모델링으로 재테크하라 => 사회학\n",
            "사회학 35.21432334887529%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9767, 0.0066, 0.0033], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 1, 2], device='cuda:0'))\n",
            "회사의 이익을 2배로 높이려면 => 경영학\n",
            "경영학 48.4378055017214%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9578, 0.0185, 0.0070], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 1, 2], device='cuda:0'))\n",
            "그림자와 칼 => 문학\n",
            "문학 25.755172574239324%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9679, 0.0103, 0.0063], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 2,  3, 10], device='cuda:0'))\n",
            "기독교교육철학의 원리와 실제 => 사회학\n",
            "종교 30.133335823117605%\n",
            "사회학 12.798501147441087%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.4341, 0.3929, 0.0814], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([2, 9, 1], device='cuda:0'))\n",
            "살육에 이르는 병 => 문학\n",
            "종교 25.18559124252036%\n",
            "문학 24.73395838792164%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9498e-01, 2.6136e-03, 8.0330e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3,  7, 10], device='cuda:0'))\n",
            "한국 금융산업의 발전 과제 => 사회학\n",
            "사회학 42.900490548214265%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9007, 0.0615, 0.0151], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 1, 2], device='cuda:0'))\n",
            "사랑이 두려운 여인 => 문학\n",
            "문학 25.401293101831275%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.5822, 0.1409, 0.0990], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([5, 9, 1], device='cuda:0'))\n",
            "인공생명 => 자연과학\n",
            "자연과학 25.51958377783052%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9868, 0.0025, 0.0023], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9, 10,  0], device='cuda:0'))\n",
            "임화 문학의 근대성 비판 => 문학\n",
            "문학 34.235631642413985%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.5331, 0.2707, 0.0638], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 1,  9, 10], device='cuda:0'))\n",
            "백년을 살아보니 => 철학\n",
            "철학 19.991620711292562%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9124, 0.0784, 0.0024], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  3,  8], device='cuda:0'))\n",
            "저항운동의 이해 => 기술과학\n",
            "역사 29.388346764308963%\n",
            "사회학 21.35667831974735%\n",
            "예술 9.964948376806284%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9569e-01, 1.3083e-03, 8.3561e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 3, 6], device='cuda:0'))\n",
            "6시그마경영 => 경영학\n",
            "경영학 44.928273709013055%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9564, 0.0149, 0.0126], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9,  8, 10], device='cuda:0'))\n",
            "대통령의 실종 => 문학\n",
            "문학 30.946378017812545%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.4972, 0.4754, 0.0082], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9,  3, 10], device='cuda:0'))\n",
            "개구리논에서 만난 아이들 => 사회학\n",
            "문학 20.462568939811806%\n",
            "사회학 20.35103754421958%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9601e-01, 6.3577e-04, 6.2987e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([0, 5, 6], device='cuda:0'))\n",
            "프로그래밍 넷스케이프 플러그인 => 총류\n",
            "총류 53.293352474080734%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9891, 0.0020, 0.0016], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([5, 0, 4], device='cuda:0'))\n",
            "현대 물리학 => 자연과학\n",
            "자연과학 57.20832901406204%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8996, 0.0744, 0.0074], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([6, 1, 2], device='cuda:0'))\n",
            "뇌로부터 마음을 읽는다 => 기술과학\n",
            "기술과학 29.411545010758417%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7648, 0.1684, 0.0284], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 2, 8], device='cuda:0'))\n",
            "집으로 가는 길 => 역사\n",
            "문학 26.29848089800767%\n",
            "종교 20.86930625409197%\n",
            "예술 14.4862811273077%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9918, 0.0025, 0.0013], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 8, 10,  9], device='cuda:0'))\n",
            "접바둑의 구상 => 예술\n",
            "예술 50.09455626209392%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9772, 0.0194, 0.0013], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  0], device='cuda:0'))\n",
            "민주노조운동의 현황과 전망 => 사회학\n",
            "사회학 36.81784233424322%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.6284, 0.1243, 0.0882], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([1, 9, 2], device='cuda:0'))\n",
            "인식과 관심 => 철학\n",
            "철학 20.526149092198537%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9693, 0.0090, 0.0087], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 8, 1], device='cuda:0'))\n",
            "갈라의 분필 => 문학\n",
            "문학 30.790677606517267%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9868, 0.0027, 0.0022], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  3,  9], device='cuda:0'))\n",
            "말하지 않는 한국사 => 역사\n",
            "역사 45.365384437711995%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9692, 0.0077, 0.0066], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([6, 3, 1], device='cuda:0'))\n",
            "대체의학의 이론과 실제 => 기술과학\n",
            "기술과학 46.34519465112193%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9536, 0.0196, 0.0062], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 3, 6], device='cuda:0'))\n",
            "1리터의 눈물 => 문학\n",
            "문학 33.235285804907335%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9748, 0.0053, 0.0052], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([5, 4, 1], device='cuda:0'))\n",
            "복소해석학의 초석 => 자연과학\n",
            "자연과학 44.88424077186203%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9924, 0.0018, 0.0014], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  7], device='cuda:0'))\n",
            "녹색청소년운동 지도자교육자료집 => 사회학\n",
            "사회학 42.24867383143049%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7090, 0.1365, 0.0579], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([1, 3, 7], device='cuda:0'))\n",
            "대한민국 행복지수 => 경영학\n",
            "철학 21.05248908919371%\n",
            "사회학 15.997014939788798%\n",
            "경영학 13.364625880404715%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.6532, 0.2004, 0.0599], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 8, 0], device='cuda:0'))\n",
            "디지털 시대의 음악 산업 => 사회학\n",
            "사회학 23.94668295094439%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8938, 0.0606, 0.0104], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 1, 3], device='cuda:0'))\n",
            "회사에서 인정받는 사람들의 5가지 습관 => 경영학\n",
            "경영학 28.60281260801173%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9559e-01, 1.5768e-03, 7.9519e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 0, 7], device='cuda:0'))\n",
            "사회복지행정 => 사회학\n",
            "사회학 39.29292519195633%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9283, 0.0383, 0.0258], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([5, 6, 7], device='cuda:0'))\n",
            "자기공명 기법에 의한 물질의 특성 규명 => 자연과학\n",
            "자연과학 35.950170331746335%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9814, 0.0117, 0.0019], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 0, 1], device='cuda:0'))\n",
            "사이버 공동체 형성의 역동적 모형 => 사회학\n",
            "사회학 27.893594905851288%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9287, 0.0431, 0.0067], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([8, 3, 7], device='cuda:0'))\n",
            "프로페셔널 공연 기획 => 예술\n",
            "예술 35.20917449472867%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.5384, 0.3867, 0.0234], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9, 10,  8], device='cuda:0'))\n",
            "청봉 가는길 => 역사\n",
            "문학 28.071838164257976%\n",
            "역사 26.43068263456544%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.6989, 0.0861, 0.0666], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 1, 8], device='cuda:0'))\n",
            "안또니오 그람쉬 => 사회학\n",
            "문학 21.88277175337783%\n",
            "철학 13.81913519522343%\n",
            "예술 12.831542756420067%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9855, 0.0045, 0.0019], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 8, 6], device='cuda:0'))\n",
            "천사는 침묵했다 => 문학\n",
            "문학 45.54989639006116%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9650e-01, 7.3286e-04, 6.2367e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 1, 6], device='cuda:0'))\n",
            "교통영향평가 => 사회학\n",
            "사회학 44.033563441530646%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9822, 0.0046, 0.0026], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 5,  3, 10], device='cuda:0'))\n",
            "현대대수학 => 자연과학\n",
            "자연과학 47.47510887750245%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9247, 0.0334, 0.0216], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9,  8, 10], device='cuda:0'))\n",
            "데카메론 => 문학\n",
            "문학 29.575262565375134%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9793, 0.0039, 0.0032], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 2, 10,  4], device='cuda:0'))\n",
            "그리스도인의 비전 => 종교\n",
            "종교 41.0024208802929%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9413, 0.0252, 0.0076], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([1, 2, 0], device='cuda:0'))\n",
            "줄기세포연구자를 위한 생명윤리 => 철학\n",
            "철학 31.983668013508574%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9195, 0.0228, 0.0158], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 1, 8], device='cuda:0'))\n",
            "교양환경과학 => 사회학\n",
            "사회학 26.325742849168112%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9762, 0.0145, 0.0031], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 8, 1], device='cuda:0'))\n",
            "시더 벤드에서 느린 왈츠를 => 문학\n",
            "문학 33.995026548874115%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9718, 0.0196, 0.0021], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  0], device='cuda:0'))\n",
            "일본의 외교정책 => 사회학\n",
            "사회학 38.764323115251955%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9312e-01, 1.8841e-03, 9.3042e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 6, 3], device='cuda:0'))\n",
            "마케팅 => 경영학\n",
            "경영학 48.96383204678253%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.5406, 0.2911, 0.1025], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([6, 5, 7], device='cuda:0'))\n",
            "우리나라 자원공학에서 물리탐사의 발전과 최근 연구동향 => 총류\n",
            "기술과학 21.572874072498923%\n",
            "자연과학 19.705501637213043%\n",
            "경영학 16.55556820047274%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8898, 0.0364, 0.0361], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 2, 1], device='cuda:0'))\n",
            "다락방에 불빛을 => 문학\n",
            "문학 31.437467203635855%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8035, 0.0626, 0.0571], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 2, 1], device='cuda:0'))\n",
            "시대의 소망 => 종교\n",
            "문학 23.150806268736513%\n",
            "종교 14.86316206894119%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7045, 0.2033, 0.0512], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 2, 1], device='cuda:0'))\n",
            "동반에서 영원으로 => 문학\n",
            "문학 26.814959580860346%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9773, 0.0079, 0.0038], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9,  3, 10], device='cuda:0'))\n",
            "4월이 되면 그녀는 => 문학\n",
            "문학 31.962214608122167%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9864, 0.0067, 0.0017], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3,  7, 10], device='cuda:0'))\n",
            "노사관계 및 노사협력의식에 관한 조사연구 => 사회학\n",
            "사회학 39.88518300447471%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9749, 0.0069, 0.0040], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9,  2, 10], device='cuda:0'))\n",
            "우리 깊은 세상 => 문학\n",
            "문학 36.82135703234391%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9915, 0.0019, 0.0019], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 5, 7], device='cuda:0'))\n",
            "신입생 실태조사 => 사회학\n",
            "사회학 50.421048251630786%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9900, 0.0051, 0.0011], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9, 10,  3], device='cuda:0'))\n",
            "사람의 나라 => 문학\n",
            "문학 35.42421416322806%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9803, 0.0031, 0.0031], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 6, 0], device='cuda:0'))\n",
            "우리시대 화제작의 밑그림 소설 => 문학\n",
            "문학 49.65080706338427%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9892, 0.0033, 0.0018], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9,  8, 10], device='cuda:0'))\n",
            "병동일기 => 문학\n",
            "문학 45.69830272475315%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.3699, 0.2972, 0.1687], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  1,  9], device='cuda:0'))\n",
            "황종희 평전 => 철학\n",
            "역사 18.049321148033748%\n",
            "철학 17.338233993500875%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7186, 0.0822, 0.0791], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 2, 1], device='cuda:0'))\n",
            "안락사의 역사 => 철학\n",
            "사회학 19.976033579910386%\n",
            "종교 13.60097004267599%\n",
            "철학 13.487114123038934%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7063, 0.1865, 0.0210], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([1, 7, 9], device='cuda:0'))\n",
            "높이 나는 새가 멀리 본다 => 철학\n",
            "철학 30.151703895447703%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9932, 0.0013, 0.0011], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 0, 6], device='cuda:0'))\n",
            "사회조사방법론 => 사회학\n",
            "사회학 47.455174773803556%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8834, 0.0652, 0.0309], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 3, 1], device='cuda:0'))\n",
            "철밥통을 깨뜨리면 부자는 시간문제 => 경영학\n",
            "경영학 34.79033227584799%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9794, 0.0050, 0.0035], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 8, 1], device='cuda:0'))\n",
            "워즈워드의 명시 => 문학\n",
            "문학 44.7230837151793%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9567, 0.0142, 0.0077], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 1, 2], device='cuda:0'))\n",
            "내 사랑 무덤 속에 담고 => 문학\n",
            "문학 32.83700952082916%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8964, 0.0476, 0.0144], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 3, 6], device='cuda:0'))\n",
            "앵커맨 => 문학\n",
            "문학 25.91246043865316%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.6132, 0.2294, 0.0936], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  8,  9], device='cuda:0'))\n",
            "현진건 => 문학\n",
            "역사 29.736177367484217%\n",
            "예술 24.168833703821257%\n",
            "문학 19.09343661833826%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9830, 0.0042, 0.0034], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 3, 1], device='cuda:0'))\n",
            "나를 위해 울어주는 버드나무 => 문학\n",
            "문학 46.091930436699336%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9942, 0.0020, 0.0013], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3,  6, 10], device='cuda:0'))\n",
            "항공 경제론 => 사회학\n",
            "사회학 35.209097297986744%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9894, 0.0066, 0.0012], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  1], device='cuda:0'))\n",
            "중국 흑룡강성 한인동포의 생활문화 => 사회학\n",
            "사회학 39.5165920148275%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9883, 0.0030, 0.0025], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 1, 3], device='cuda:0'))\n",
            "시간관리학 => 경영학\n",
            "경영학 45.86668048058765%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.6316, 0.1768, 0.0674], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([1, 2, 9], device='cuda:0'))\n",
            "자연의 원리 땅의 이치 => 철학\n",
            "철학 20.90658848402448%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8538, 0.0669, 0.0357], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9, 10,  3], device='cuda:0'))\n",
            "잊지 않겠다고 맹세한 내가 있었다 => 문학\n",
            "문학 22.4640602262686%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9805, 0.0077, 0.0034], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 8, 2], device='cuda:0'))\n",
            "백주의 악마 => 문학\n",
            "문학 34.93444650171898%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9016, 0.0679, 0.0179], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  9], device='cuda:0'))\n",
            "대통령의 승부수 => 사회학\n",
            "사회학 29.410472449623057%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9543, 0.0101, 0.0100], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 1, 8], device='cuda:0'))\n",
            "미칼레스대장 => 문학\n",
            "문학 32.397164453793415%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7236, 0.1741, 0.0806], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([1, 3, 7], device='cuda:0'))\n",
            "백만장자처럼 생각하라 => 철학\n",
            "철학 23.344698953983002%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9798, 0.0040, 0.0039], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9,  1, 10], device='cuda:0'))\n",
            "지금도 쓸쓸하냐 => 문학\n",
            "문학 34.32163962921526%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8552, 0.0542, 0.0381], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 6, 3], device='cuda:0'))\n",
            "만들어진 남자 => 문학\n",
            "문학 20.83952216832638%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8250, 0.0696, 0.0365], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 3, 7], device='cuda:0'))\n",
            "보이지 않는 손 => 문학\n",
            "문학 25.465333347705684%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7890, 0.1247, 0.0485], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([1, 2, 7], device='cuda:0'))\n",
            "믿으면 이루어지는 꿈의 원리 => 철학\n",
            "철학 29.96127117816086%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8351, 0.0836, 0.0362], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  3,  4], device='cuda:0'))\n",
            "한중 인문교류와 한국학연구 동향 => 역사\n",
            "역사 28.034927784847117%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9709, 0.0211, 0.0018], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 3, 2], device='cuda:0'))\n",
            "조직혁신과 창조적 경영 => 경영학\n",
            "경영학 39.574077795487206%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9093, 0.0425, 0.0138], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([1, 4, 3], device='cuda:0'))\n",
            "기호 학파의 철학 사상 => 철학\n",
            "철학 35.47072026486037%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9506, 0.0395, 0.0031], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  3,  0], device='cuda:0'))\n",
            "미국의 동아시아 개입의 역사적 원형과 20세기초 한미 관계 연구 => 역사\n",
            "역사 34.30436378555702%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9917, 0.0020, 0.0013], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([0, 5, 6], device='cuda:0'))\n",
            "국립디지털도서관 운영전략 세부계획 보고서 => 총류\n",
            "총류 42.569095925493784%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8794, 0.0950, 0.0047], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([8, 9, 1], device='cuda:0'))\n",
            "미스틱 => 예술\n",
            "예술 37.07014169035465%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9496, 0.0283, 0.0139], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 3, 6], device='cuda:0'))\n",
            "객실승무원 실전면접 => 경영학\n",
            "경영학 30.131531291609583%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.4487, 0.2979, 0.1101], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([1, 9, 3], device='cuda:0'))\n",
            "사랑의 학습지도법 => 사회학\n",
            "철학 20.78732712962426%\n",
            "문학 19.221754802012136%\n",
            "사회학 15.418658349807373%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9263, 0.0589, 0.0038], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 9, 6], device='cuda:0'))\n",
            "공장과 신화 => 사회학\n",
            "사회학 25.203267444769185%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9013, 0.0560, 0.0139], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([5, 6, 3], device='cuda:0'))\n",
            "기술여행 => 자연과학\n",
            "자연과학 32.14320992358765%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9398, 0.0467, 0.0038], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  3,  9], device='cuda:0'))\n",
            "근대 일본의 사회사 => 역사\n",
            "역사 31.149172583962663%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9931, 0.0017, 0.0016], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 1, 2], device='cuda:0'))\n",
            "오동잎 잎새마다 달이 뜨면 => 문학\n",
            "문학 44.35807251818327%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9677e-01, 7.0934e-04, 5.7490e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  1], device='cuda:0'))\n",
            "특수교육학개론 => 사회학\n",
            "사회학 46.19145482587499%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.6771, 0.0682, 0.0592], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 3, 5], device='cuda:0'))\n",
            "물의 무게 => 문학\n",
            "문학 20.062264370384728%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9894, 0.0021, 0.0017], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 2, 3], device='cuda:0'))\n",
            "현대시의 논리와 변명 => 문학\n",
            "문학 39.9282114232787%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9843, 0.0084, 0.0033], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 7, 6], device='cuda:0'))\n",
            "IT경제교육 => 사회학\n",
            "사회학 37.78374636213353%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9610, 0.0188, 0.0143], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([6, 5, 7], device='cuda:0'))\n",
            "모래지반의 액상화 => 기술과학\n",
            "기술과학 29.677979506726007%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9149, 0.0623, 0.0115], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  9], device='cuda:0'))\n",
            "한국의 설화 => 사회학\n",
            "사회학 30.224984823991463%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9829, 0.0040, 0.0035], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  6], device='cuda:0'))\n",
            "경제사상과 교육 => 사회학\n",
            "사회학 31.95792020037018%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9728, 0.0075, 0.0063], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 2, 1], device='cuda:0'))\n",
            "삭발하고 본 세상 => 문학\n",
            "문학 34.06412727683977%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9142, 0.0440, 0.0138], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 1, 3], device='cuda:0'))\n",
            "제발 조용히 좀 해요 => 문학\n",
            "문학 33.27189255614664%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.4755, 0.2875, 0.1931], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([2, 9, 1], device='cuda:0'))\n",
            "씨뿌리는 비유 => 종교\n",
            "종교 23.68193699643429%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9546, 0.0321, 0.0026], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([2, 1, 0], device='cuda:0'))\n",
            "교회가 꼭 대답해야 할 윤리 문제들 => 종교\n",
            "종교 32.323294978635104%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7947, 0.1573, 0.0127], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([1, 7, 2], device='cuda:0'))\n",
            "성공의 열쇠는 적성이나 재능이 아니라 집중력이다 => 철학\n",
            "철학 27.71305288472388%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9223e-01, 4.5842e-03, 9.0305e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 7, 0], device='cuda:0'))\n",
            "고용주지원 보육서비스의 다양화 방안 => 사회학\n",
            "사회학 45.83782905913988%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.5310, 0.1878, 0.0827], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 1, 3], device='cuda:0'))\n",
            "창의적 콘셉트와 파워풀 라이팅 => 경영학\n",
            "경영학 18.788993105651883%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.7914, 0.1843, 0.0084], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  0], device='cuda:0'))\n",
            "한국 중 고교 사회생활 교과서에 나타난 미국과 미국문화 => 역사\n",
            "사회학 26.526808342888227%\n",
            "역사 21.595699492646133%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9367, 0.0427, 0.0074], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 6, 9], device='cuda:0'))\n",
            "한국 소아의 정상치 => 사회학\n",
            "사회학 27.532195459203813%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9692, 0.0120, 0.0082], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  8,  3], device='cuda:0'))\n",
            "중세의 빛과 그림자 => 역사\n",
            "역사 37.82543120499951%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9626, 0.0156, 0.0051], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 8, 7], device='cuda:0'))\n",
            "러브 발라드 => 문학\n",
            "문학 38.29749392990071%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9801, 0.0042, 0.0030], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 8, 10,  9], device='cuda:0'))\n",
            "예술가와 디자이너 => 예술\n",
            "예술 48.177459306949196%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9902, 0.0024, 0.0017], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  9], device='cuda:0'))\n",
            "중국 조선족 교육사 => 사회학\n",
            "사회학 36.09599230381327%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8092, 0.1001, 0.0278], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([0, 9, 7], device='cuda:0'))\n",
            "조선일보 공화국 => 총류\n",
            "총류 26.11097447233684%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9796, 0.0042, 0.0031], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 7,  9, 10], device='cuda:0'))\n",
            "회계감사 => 경영학\n",
            "경영학 39.45326759911845%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9694, 0.0080, 0.0069], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  4], device='cuda:0'))\n",
            "독학의 기술 => 사회학\n",
            "사회학 31.05391914118033%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9412, 0.0297, 0.0137], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 3, 1], device='cuda:0'))\n",
            "인재전쟁 => 경영학\n",
            "경영학 33.914254137912444%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9534, 0.0136, 0.0085], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9, 10,  5], device='cuda:0'))\n",
            "바다 끊어지지 않는 인연 => 문학\n",
            "문학 27.74674822219478%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9741, 0.0080, 0.0070], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 2, 3], device='cuda:0'))\n",
            "붉은 태양이 거미를 문다 => 문학\n",
            "문학 27.685828624352336%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9897, 0.0027, 0.0022], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([9, 1, 8], device='cuda:0'))\n",
            "숭어의 꿈 => 문학\n",
            "문학 42.55529751215697%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9689, 0.0073, 0.0068], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 8, 5], device='cuda:0'))\n",
            "한국공간구조론 => 사회학\n",
            "사회학 27.9671395148827%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9902, 0.0028, 0.0021], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  6], device='cuda:0'))\n",
            "현대 초등수학 교육론 => 사회학\n",
            "사회학 47.262358533424994%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.8873, 0.0722, 0.0108], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9,  8, 10], device='cuda:0'))\n",
            "아바 => 문학\n",
            "문학 27.371063966172564%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9351, 0.0512, 0.0044], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 7, 1], device='cuda:0'))\n",
            "임금인상활동지침 => 사회학\n",
            "사회학 35.529560798845154%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9811e-01, 5.0187e-04, 3.4525e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 3, 10,  0], device='cuda:0'))\n",
            "한국에서 마르크스주의 경제학의 도입과 전개과정 => 사회학\n",
            "사회학 44.056706315935386%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9785, 0.0068, 0.0046], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([ 9, 10,  8], device='cuda:0'))\n",
            "상록수 => 문학\n",
            "문학 34.08567770842557%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9028, 0.0414, 0.0354], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([10,  9,  2], device='cuda:0'))\n",
            "황제 프리드리히 2세의 생애 => 역사\n",
            "역사 29.629789385354524%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9929, 0.0015, 0.0012], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 4, 2], device='cuda:0'))\n",
            "CPA 재무회계연습 => 경영학\n",
            "경영학 45.48431992964953%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9897, 0.0041, 0.0017], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([7, 3, 6], device='cuda:0'))\n",
            "광고논증 => 경영학\n",
            "경영학 52.403427900798654%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([9.9658e-01, 1.1225e-03, 4.8310e-04], device='cuda:0',\n",
            "       grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 9, 1], device='cuda:0'))\n",
            "우리는 남성 해방 선언 => 사회학\n",
            "사회학 33.396803451346976%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9916, 0.0026, 0.0013], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([3, 7, 1], device='cuda:0'))\n",
            "현대 지역사회개발의 이해 => 사회학\n",
            "사회학 37.03706220873261%\n",
            "max for title:  torch.return_types.topk(\n",
            "values=tensor([0.9898, 0.0018, 0.0016], device='cuda:0', grad_fn=<TopkBackward0>),\n",
            "indices=tensor([0, 7, 8], device='cuda:0'))\n",
            "문탁네트워크가 사랑한 책들 => 총류\n",
            "총류 46.26843465313449%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-bb3ef4876833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0mvalid_length\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-0e5d53916b5f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ids, valid_length, segment_ids)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m    985\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0membeddings\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mposition_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "# print(test['제목'].iloc(0))\n",
        "# toselftest = [\"테스트1\",\"테스트2\",\"테스트3\"]\n",
        "\n",
        "labels = {0:'총류',\n",
        "          1:'철학',\n",
        "          2:'종교',\n",
        "          3:'사회학',\n",
        "          4:'언어',\n",
        "          5:'자연과학',\n",
        "          6:'기술과학',\n",
        "          7:'경영학',\n",
        "          8:'예술',\n",
        "          9: '문학',\n",
        "          10:'역사'\n",
        "}\n",
        "\n",
        "# selftest = DataFrame({\n",
        "#   'value': toselftest,\n",
        "#   'null': [0 for x in toselftest]\n",
        "# })\n",
        "\n",
        "# selftest.to_csv(\"/content/gdrive/MyDrive/LibraryCsv/test.txt\", sep=\"\\t\")\n",
        "# dataset_selftest = nlp.data.TSVDataset(\"/content/gdrive/MyDrive/LibraryCsv/test.txt\", field_indices=[1,2], num_discard_samples=1)\n",
        "# data_selftest = BERTDataset(dataset_selftest, 0, 1, tok, max_len, True, False)\n",
        "# selftest_dataloader = torch.utils.data.DataLoader(data_selftest, batch_size=1, num_workers=1)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=1, num_workers=5)\n",
        "\n",
        "print(len(test))\n",
        "print(len(test_dataloader))\n",
        "\n",
        "correct = 0\n",
        "for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
        "      token_ids = token_ids.long().to(device)\n",
        "      segment_ids = segment_ids.long().to(device)\n",
        "      valid_length= valid_length\n",
        "      label = label.long().to(device)\n",
        "      out = model(token_ids, valid_length, segment_ids)\n",
        "      prediction = out.cpu().detach().numpy()[0]\n",
        "      minval = prediction.min()\n",
        "      prediction = [x-minval for x in prediction]\n",
        "      sumval = sum(prediction)\n",
        "\n",
        "      answer = int(test['청구번호'].iloc[batch_id])\n",
        "      print(\"{} => {}\".format(test['제목'].iloc[batch_id], labels[answer]))\n",
        "      top3 = 0\n",
        "      for index, score in sorted(enumerate(prediction), reverse = True, key = lambda prediction:prediction[1]):\n",
        "        print(\"{} {}%\".format(labels[index], score*100/sumval))\n",
        "        if index == answer:\n",
        "          correct += 1\n",
        "          # print(\"Success\")\n",
        "          break\n",
        "        else:\n",
        "          top3 += 1\n",
        "          if top3 == 3: \n",
        "            # print(\"Failed\")\n",
        "            break\n",
        "print(correct)\n",
        "print(len(test_dataloader))\n",
        "print(correct*100/len(test_dataloader))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b94c93b8beec48c194865c94d465fec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e9f7a3c744f4b7abd48ea6c472155c1",
              "IPY_MODEL_60da93ce4faa4991ac85514460d7fa2d",
              "IPY_MODEL_15857349ecc44fd68527ecf4f779f984"
            ],
            "layout": "IPY_MODEL_5813dc7905a947bbb2dd468783c952bd"
          }
        },
        "4e9f7a3c744f4b7abd48ea6c472155c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d9c9181b92469fb791353760607965",
            "placeholder": "​",
            "style": "IPY_MODEL_69621886ad8b4ffd8bddae3b66eccc35",
            "value": "  0%"
          }
        },
        "60da93ce4faa4991ac85514460d7fa2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6724886aea67497abab927b4f8740e44",
            "max": 1141,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3ab92da9e3c483eb35680f6b45ed897",
            "value": 4
          }
        },
        "15857349ecc44fd68527ecf4f779f984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5ddea227ca745e696ded7e3562cb43c",
            "placeholder": "​",
            "style": "IPY_MODEL_6a4fdaf0bd5e4348a191fc30fe95afd8",
            "value": " 4/1141 [00:03&lt;12:13,  1.55it/s]"
          }
        },
        "5813dc7905a947bbb2dd468783c952bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d9c9181b92469fb791353760607965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69621886ad8b4ffd8bddae3b66eccc35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6724886aea67497abab927b4f8740e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3ab92da9e3c483eb35680f6b45ed897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5ddea227ca745e696ded7e3562cb43c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a4fdaf0bd5e4348a191fc30fe95afd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4930f1e45516485baffc9c970d0bd4c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1669351db5cb489c9c5ec3f56077627d",
              "IPY_MODEL_3355b8221c5b49bc8e7266a43de9a1e2",
              "IPY_MODEL_22f223c2a6c9440ca76cb8ec276ad2d0"
            ],
            "layout": "IPY_MODEL_40ccf7024f0d4ca2a7516757335e2162"
          }
        },
        "1669351db5cb489c9c5ec3f56077627d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b194d80ec288429196a867b6b3c20428",
            "placeholder": "​",
            "style": "IPY_MODEL_fbe6b9028ff94dbe8d050fa35072a2ed",
            "value": "  1%"
          }
        },
        "3355b8221c5b49bc8e7266a43de9a1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc1be9a3b5c34c9babab176a9913c8de",
            "max": 18249,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93f5a725217e49bb829f0df47ada296e",
            "value": 221
          }
        },
        "22f223c2a6c9440ca76cb8ec276ad2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd3ea090a87545cb9a80147780c7a6d4",
            "placeholder": "​",
            "style": "IPY_MODEL_799a03e5b04b4b29af262467458d6cdb",
            "value": " 221/18249 [00:03&lt;05:12, 57.67it/s]"
          }
        },
        "40ccf7024f0d4ca2a7516757335e2162": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b194d80ec288429196a867b6b3c20428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbe6b9028ff94dbe8d050fa35072a2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc1be9a3b5c34c9babab176a9913c8de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93f5a725217e49bb829f0df47ada296e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd3ea090a87545cb9a80147780c7a6d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "799a03e5b04b4b29af262467458d6cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}